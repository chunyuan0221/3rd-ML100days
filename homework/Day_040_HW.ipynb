{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "使用 Sklearn 中的 Lasso, Ridge 模型，來訓練各種資料集，務必了解送進去模型訓練的**資料型態**為何，也請了解模型中各項參數的意義。\n",
    "\n",
    "機器學習的模型非常多種，但要訓練的資料多半有固定的格式，確保你了解訓練資料的格式為何，這樣在應用新模型時，就能夠最快的上手開始訓練！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習時間\n",
    "試著使用 sklearn datasets 的其他資料集 (boston, ...)，來訓練自己的線性迴歸模型，並加上適當的正則化來觀察訓練情形。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Boston House Price Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = datasets.load_boston()\n",
    "x_train, x_test, Y_train, Y_test = train_test_split(boston.data, boston.target, test_size=0.2, random_state=0)\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(x_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_pred = linear_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear Regression MSE :　33.44897999767654\n"
     ]
    }
   ],
   "source": [
    "MSE = metrics.mean_squared_error(Y_test, Y_pred)\n",
    "print(f'linear Regression MSE :　{MSE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.19443447e-01,  4.47799511e-02,  5.48526168e-03,  2.34080361e+00,\n",
       "       -1.61236043e+01,  3.70870901e+00, -3.12108178e-03, -1.38639737e+00,\n",
       "        2.44178327e-01, -1.09896366e-02, -1.04592119e+00,  8.11010693e-03,\n",
       "       -4.92792725e-01])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Lasso_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE with Lasso : 41.700096799949\n"
     ]
    }
   ],
   "source": [
    "Lasso_model = Lasso(alpha=1)\n",
    "Lasso_model.fit(x_train, Y_train)\n",
    "Y_pred = Lasso_model.predict(x_test)\n",
    "MSE = metrics.mean_squared_error(Y_test, Y_pred)\n",
    "print(f'Linear Regression MSE with Lasso : {MSE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05889028,  0.05317657, -0.        ,  0.        , -0.        ,\n",
       "        0.67954962,  0.01684077, -0.6487664 ,  0.198738  , -0.01399421,\n",
       "       -0.86421958,  0.00660309, -0.73120957])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lasso_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Ridge_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE with Ridge : 34.23160611061538\n"
     ]
    }
   ],
   "source": [
    "Ridge_model = Ridge(alpha=1)\n",
    "Ridge_model.fit(x_train, Y_train)\n",
    "Y_pred = Ridge_model.predict(x_test)\n",
    "MSE = metrics.mean_squared_error(Y_test, Y_pred)\n",
    "print(f'Linear Regression MSE with Ridge : {MSE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.16807614e-01,  4.60034842e-02, -2.37620690e-02,  2.27814972e+00,\n",
       "       -8.55779612e+00,  3.75513528e+00, -1.04143035e-02, -1.28009479e+00,\n",
       "        2.22037885e-01, -1.15255734e-02, -9.69288272e-01,  8.53481709e-03,\n",
       "       -4.98849035e-01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridge_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 結論：\n",
    "    1. 我們用MSE來算實際值與我們設計出的模型誤差有多少，結果原始的模型具有較少的誤差，而L1、L2都具有較高的誤差值。\n",
    "    2. 透過coef我們可以看到係數值(weight)的變化，Day039有提到Lasso正規化會使部分係數降至0，而Ridge正規化會使共線性高的係數逼近0。\n",
    "    3. 透過GridSearchCV我們可以試著找出最佳解的alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Wine Class Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data & split\n",
    "wine = datasets.load_wine()\n",
    "x_train, x_test, Y_train, Y_test = train_test_split(wine.data, wine.target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. LogisticRegression with no regularization\n",
    "***\n",
    "- LogisticRegression()中有一個參數penalty，他是用來表示是否使用正規化(regularization)，預設是'l2'\n",
    "- 這邊先測試未使用正規化(regularization)的準確率如何，因此要把penalty設定為'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Accuracy : 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "logist_model = LogisticRegression(penalty='none', solver='lbfgs')\n",
    "logist_model.fit(x_train, Y_train)\n",
    "Y_pred = logist_model.predict(x_test)\n",
    "acc = metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(f'LogisticRegression Accuracy : {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.12719592e+00,  2.39042453e+00,  2.15072872e+00,\n",
       "        -8.74081406e-01, -5.52566763e-02,  3.17321773e-01,\n",
       "         3.73948655e+00,  1.43578499e-01, -4.70857387e-01,\n",
       "         3.69029239e-01, -4.14700281e-01,  2.29891069e+00,\n",
       "         2.85211037e-02],\n",
       "       [ 3.20599406e+00, -3.05498475e+00, -2.15690535e+00,\n",
       "         5.98335701e-01, -8.98709600e-02, -3.73554987e-01,\n",
       "         4.04315307e-01,  3.20982800e-01,  2.57247200e+00,\n",
       "        -5.15112790e+00,  1.36376800e+00, -8.32887846e-01,\n",
       "        -2.22883578e-02],\n",
       "       [-1.70688972e+01,  1.72329661e+01, -6.22795977e-01,\n",
       "         7.92439146e-01,  1.40334135e+00, -1.75546061e+01,\n",
       "        -3.80548547e+01,  7.12283723e-01, -1.59545908e+01,\n",
       "         3.82874727e+01, -9.31314985e+00, -3.07268026e+01,\n",
       "         1.12219424e-02]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logist_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. LogisticRegression with L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "L1_model = LogisticRegression(penalty='l1')\n",
    "L1_model.fit(x_train, Y_train)\n",
    "#Y_pred = L1_model.predict(x_test)\n",
    "#acc = metrics.accuracy_score(Y_test, Y_pred)\n",
    "score = L1_model.score(x_test, Y_test)\n",
    "#print(acc)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.39142630e-01,  4.86052294e-01,  0.00000000e+00,\n",
       "        -5.77148947e-01, -5.70397488e-02,  0.00000000e+00,\n",
       "         2.05670899e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.58573496e-02],\n",
       "       [ 1.12157620e+00, -1.13375215e+00, -4.53008836e-01,\n",
       "         2.31851863e-01, -9.08497440e-03,  0.00000000e+00,\n",
       "         3.37514911e-03,  0.00000000e+00,  1.74087212e+00,\n",
       "        -2.22211428e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -1.17398421e-02],\n",
       "       [ 0.00000000e+00,  1.21059728e-01,  0.00000000e+00,\n",
       "         6.48974001e-03,  1.51530605e-02,  0.00000000e+00,\n",
       "        -3.17211986e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.41371031e+00,  0.00000000e+00, -1.60028331e+00,\n",
       "        -2.04284910e-03]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. LogisticRegression with L2 regularization\n",
    "***\n",
    "- 因為LogisticRegression預設penalty='l2'，因此不需要做更改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "L2_model = LogisticRegression()\n",
    "L2_model.fit(x_train, Y_train)\n",
    "Y_pred = L2_model.predict(x_test)\n",
    "acc = metrics.accuracy_score(Y_test, Y_pred)\n",
    "#score = L2_model.score(x_test, Y_test)\n",
    "print(acc)\n",
    "#print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.44368761e-01,  6.08577842e-01,  7.65204263e-01,\n",
       "        -6.31559488e-01, -4.28209531e-02,  1.59693228e-01,\n",
       "         1.34856745e+00,  8.34724547e-02, -2.43463699e-01,\n",
       "        -5.45195152e-02, -1.25504087e-01,  8.04776031e-01,\n",
       "         1.58161999e-02],\n",
       "       [ 8.55714873e-01, -1.01077691e+00, -8.81924804e-01,\n",
       "         2.49844566e-01,  1.32374297e-03,  1.42640370e-01,\n",
       "         3.33911682e-01,  1.17291960e-01,  1.02891601e+00,\n",
       "        -1.87763301e+00,  5.67854908e-01,  9.64181237e-02,\n",
       "        -1.13359307e-02],\n",
       "       [-2.86370705e-01,  5.21029698e-01,  6.84632488e-02,\n",
       "         7.24896195e-02,  3.06567693e-02, -4.53372738e-01,\n",
       "        -1.71648436e+00, -3.32455970e-03, -8.78924626e-01,\n",
       "         1.23488978e+00, -4.22922225e-01, -1.28403533e+00,\n",
       "        -1.65477024e-03]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 結論：\n",
    "    1. 從準確率來看，不使用正規化下的準確率和L2正規化的準確率一樣是0.944，而L1正規化的準確率為0.916\n",
    "    2. 我們可以從coef來觀察不同模式下，係數(weight)是否真的有所不同\n",
    "        1. Lasso:部分係數為0\n",
    "        2. Ridge:部分係數逼近0(ex: e-02、e-03)\n",
    "        3. 我們也可以看到Lasso係數為0的項與Ridge係數逼近0的項相似\n",
    "        4. Ridge的準確率隨然和未使用正規化的準確率一樣，但係數(weight)卻並不相同"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
