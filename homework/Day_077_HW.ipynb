{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Day_077_HW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chunyuan0221/3rd-ML100days/blob/master/Day_077_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XLerHJV-QvE",
        "colab_type": "text"
      },
      "source": [
        "## Work\n",
        "1. 請將 Epoch 加到 500 個，並觀察 learning curve 的走勢\n",
        "2. 請將 Optimizer 換成 SGD，並觀察 learning curve 的走勢"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wL5qEes-QvH",
        "colab_type": "code",
        "outputId": "b4c2f078-b065-4379-c4c3-195ff6fab51f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout, Input\n",
        "from keras import optimizers\n",
        "#from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "# 本作業可以不需使用 GPU, 將 GPU 設定為 \"無\" (若有 GPU 且想開啟，可設為 \"0\")\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E-ftD9t-QvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 從 Keras 的內建功能中，取得 train 與 test 資料集\n",
        "def load_data():\n",
        "    (train_x, train_y), (test_x, test_y) = cifar10.load_data()\n",
        "    print(f'Train_set: X={train_x.shape}, Y={train_y.shape}')\n",
        "    print(f'Test_set: X={test_x.shape}, Y={test_y.shape}')\n",
        "    \n",
        "    train_x = train_x.reshape(len(train_x), -1)\n",
        "    test_x = test_x.reshape(len(test_x), -1)\n",
        "    print('X data:RGB to one channel')\n",
        "    print(f'X_Train: X={train_x.shape}')\n",
        "    print(f'X_Test: X={test_x.shape}')\n",
        "    \n",
        "    train_y = to_categorical(train_y)\n",
        "    test_y = to_categorical(test_y)\n",
        "    print('After OneHotEncoding')\n",
        "    print(f'Train_set: Y={train_y.shape}')\n",
        "    print(f'Test_set: Y={test_y.shape}')\n",
        "    return train_x, train_y, test_x, test_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0N-8W_6-QvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scaling_pixel(train, test):\n",
        "    norm_train_x = train_x / 255.0\n",
        "    norm_test_x = test_x / 255.0\n",
        "    return norm_train_x, norm_test_x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "cYcik2j1-QvT",
        "colab_type": "code",
        "outputId": "c2d5f681-b83d-4bb6-f3be-d79590feb39f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "train_x, train_y, test_x, test_y = load_data()\n",
        "train_x, test_x = scaling_pixel(train_x, test_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train_set: X=(50000, 32, 32, 3), Y=(50000, 1)\n",
            "Test_set: X=(10000, 32, 32, 3), Y=(10000, 1)\n",
            "X data:RGB to one channel\n",
            "X_Train: X=(50000, 3072)\n",
            "X_Test: X=(10000, 3072)\n",
            "After OneHotEncoding\n",
            "Train_set: Y=(50000, 10)\n",
            "Test_set: Y=(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC755vwC-QvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_mlp(in_shape, opt):\n",
        "    model = Sequential()\n",
        "    input_layer = Input([in_shape[1]])\n",
        "    x = Dense(units=512, activation='relu')(input_layer)\n",
        "    #x = Dropout(0.2)(x)\n",
        "    x = Dense(units=256, activation='relu')(x)\n",
        "    #x = Dropout(0.2)(x)\n",
        "    x = Dense(units=128, activation='relu')(x)\n",
        "    #x = Dropout(0.2)(x)\n",
        "    x = Dense(units=64, activation='relu')(x)\n",
        "    #x = Dropout(0.25)(x)\n",
        "    out = Dense(units=10, activation='softmax')(x)\n",
        "    model = keras.models.Model(inputs=input_layer, outputs=out)\n",
        "    \n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSNIT6UU-QvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = optimizers.SGD(lr=0.01, momentum=0.8)\n",
        "model = build_mlp(train_x.shape, opt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlRV-nZeCXNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = keras.optimizers.Adam(lr=0.001)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FKM73-eBwN3",
        "colab_type": "code",
        "outputId": "8cd948d2-f1df-4915-f261-e97186c689b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 1,746,506\n",
            "Trainable params: 1,746,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "QMFjYPNw-Qvd",
        "colab_type": "code",
        "outputId": "9463b6d5-d2ba-4876-de78-f98add1a7ced",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\"\n",
        "設定要訓練的 Epoch 數\n",
        "\"\"\"\n",
        "model.fit(train_x, train_y, \n",
        "          epochs=500, \n",
        "          batch_size=256, \n",
        "          validation_data=(test_x, test_y),\n",
        "          shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/500\n",
            "50000/50000 [==============================] - 12s 238us/step - loss: 1.9502 - acc: 0.2926 - val_loss: 1.8495 - val_acc: 0.3439\n",
            "Epoch 2/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.7349 - acc: 0.3781 - val_loss: 1.6969 - val_acc: 0.4049\n",
            "Epoch 3/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.6382 - acc: 0.4186 - val_loss: 1.6146 - val_acc: 0.4284\n",
            "Epoch 4/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5736 - acc: 0.4398 - val_loss: 1.5795 - val_acc: 0.4235\n",
            "Epoch 5/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5230 - acc: 0.4571 - val_loss: 1.6092 - val_acc: 0.4268\n",
            "Epoch 6/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.4814 - acc: 0.4713 - val_loss: 1.4953 - val_acc: 0.4642\n",
            "Epoch 7/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.4516 - acc: 0.4831 - val_loss: 1.4480 - val_acc: 0.4809\n",
            "Epoch 8/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.4226 - acc: 0.4970 - val_loss: 1.5541 - val_acc: 0.4516\n",
            "Epoch 9/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3925 - acc: 0.5053 - val_loss: 1.4252 - val_acc: 0.4920\n",
            "Epoch 10/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3650 - acc: 0.5153 - val_loss: 1.4630 - val_acc: 0.4766\n",
            "Epoch 11/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3388 - acc: 0.5226 - val_loss: 1.4059 - val_acc: 0.4995\n",
            "Epoch 12/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3169 - acc: 0.5299 - val_loss: 1.4473 - val_acc: 0.4836\n",
            "Epoch 13/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2865 - acc: 0.5422 - val_loss: 1.4173 - val_acc: 0.4954\n",
            "Epoch 14/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2784 - acc: 0.5458 - val_loss: 1.4023 - val_acc: 0.5001\n",
            "Epoch 15/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2527 - acc: 0.5565 - val_loss: 1.4005 - val_acc: 0.5071\n",
            "Epoch 16/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2313 - acc: 0.5633 - val_loss: 1.4139 - val_acc: 0.5028\n",
            "Epoch 17/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2057 - acc: 0.5715 - val_loss: 1.3585 - val_acc: 0.5186\n",
            "Epoch 18/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1951 - acc: 0.5769 - val_loss: 1.3945 - val_acc: 0.5135\n",
            "Epoch 19/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1717 - acc: 0.5848 - val_loss: 1.3462 - val_acc: 0.5249\n",
            "Epoch 20/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1493 - acc: 0.5913 - val_loss: 1.3354 - val_acc: 0.5333\n",
            "Epoch 21/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1305 - acc: 0.5974 - val_loss: 1.3656 - val_acc: 0.5197\n",
            "Epoch 22/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1158 - acc: 0.6020 - val_loss: 1.4136 - val_acc: 0.5098\n",
            "Epoch 23/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1030 - acc: 0.6073 - val_loss: 1.3563 - val_acc: 0.5263\n",
            "Epoch 24/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0866 - acc: 0.6128 - val_loss: 1.3790 - val_acc: 0.5286\n",
            "Epoch 25/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.0663 - acc: 0.6188 - val_loss: 1.3784 - val_acc: 0.5244\n",
            "Epoch 26/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.0495 - acc: 0.6276 - val_loss: 1.3477 - val_acc: 0.5290\n",
            "Epoch 27/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.0328 - acc: 0.6312 - val_loss: 1.5130 - val_acc: 0.4912\n",
            "Epoch 28/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.0100 - acc: 0.6395 - val_loss: 1.4137 - val_acc: 0.5195\n",
            "Epoch 29/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 0.9976 - acc: 0.6446 - val_loss: 1.3152 - val_acc: 0.5446\n",
            "Epoch 30/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.9752 - acc: 0.6524 - val_loss: 1.3901 - val_acc: 0.5259\n",
            "Epoch 31/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.9508 - acc: 0.6615 - val_loss: 1.3847 - val_acc: 0.5320\n",
            "Epoch 32/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 0.9424 - acc: 0.6639 - val_loss: 1.4131 - val_acc: 0.5227\n",
            "Epoch 33/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 0.9285 - acc: 0.6682 - val_loss: 1.4055 - val_acc: 0.5281\n",
            "Epoch 34/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.9107 - acc: 0.6775 - val_loss: 1.3848 - val_acc: 0.5340\n",
            "Epoch 35/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.9003 - acc: 0.6798 - val_loss: 1.4720 - val_acc: 0.5203\n",
            "Epoch 36/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.8729 - acc: 0.6896 - val_loss: 1.4519 - val_acc: 0.5258\n",
            "Epoch 37/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.8599 - acc: 0.6928 - val_loss: 1.4121 - val_acc: 0.5419\n",
            "Epoch 38/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.8431 - acc: 0.7011 - val_loss: 1.4155 - val_acc: 0.5418\n",
            "Epoch 39/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.8363 - acc: 0.7002 - val_loss: 1.4711 - val_acc: 0.5283\n",
            "Epoch 40/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 0.8161 - acc: 0.7100 - val_loss: 1.4077 - val_acc: 0.5428\n",
            "Epoch 41/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 0.8129 - acc: 0.7077 - val_loss: 1.4348 - val_acc: 0.5358\n",
            "Epoch 42/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 0.7879 - acc: 0.7185 - val_loss: 1.4236 - val_acc: 0.5455\n",
            "Epoch 43/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 0.7559 - acc: 0.7314 - val_loss: 1.4705 - val_acc: 0.5397\n",
            "Epoch 44/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.7670 - acc: 0.7253 - val_loss: 1.5195 - val_acc: 0.5298\n",
            "Epoch 45/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.7316 - acc: 0.7410 - val_loss: 1.5798 - val_acc: 0.5156\n",
            "Epoch 46/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.7160 - acc: 0.7471 - val_loss: 1.6192 - val_acc: 0.5117\n",
            "Epoch 47/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.7025 - acc: 0.7518 - val_loss: 1.5682 - val_acc: 0.5336\n",
            "Epoch 48/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 0.6979 - acc: 0.7507 - val_loss: 1.5882 - val_acc: 0.5316\n",
            "Epoch 49/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.6751 - acc: 0.7588 - val_loss: 1.5175 - val_acc: 0.5285\n",
            "Epoch 50/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.6544 - acc: 0.7668 - val_loss: 1.6630 - val_acc: 0.5225\n",
            "Epoch 51/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.6478 - acc: 0.7675 - val_loss: 1.6152 - val_acc: 0.5307\n",
            "Epoch 52/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.6283 - acc: 0.7763 - val_loss: 1.6571 - val_acc: 0.5291\n",
            "Epoch 53/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.6171 - acc: 0.7792 - val_loss: 1.6163 - val_acc: 0.5405\n",
            "Epoch 54/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.5967 - acc: 0.7873 - val_loss: 1.7318 - val_acc: 0.5244\n",
            "Epoch 55/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.6005 - acc: 0.7843 - val_loss: 1.7455 - val_acc: 0.5292\n",
            "Epoch 56/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.5687 - acc: 0.7967 - val_loss: 1.6855 - val_acc: 0.5338\n",
            "Epoch 57/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.5633 - acc: 0.7992 - val_loss: 1.7970 - val_acc: 0.5166\n",
            "Epoch 58/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.5394 - acc: 0.8066 - val_loss: 1.7024 - val_acc: 0.5413\n",
            "Epoch 59/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.5163 - acc: 0.8157 - val_loss: 1.7118 - val_acc: 0.5416\n",
            "Epoch 60/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 0.5328 - acc: 0.8069 - val_loss: 1.8468 - val_acc: 0.5216\n",
            "Epoch 61/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.5110 - acc: 0.8162 - val_loss: 1.8048 - val_acc: 0.5340\n",
            "Epoch 62/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.5015 - acc: 0.8213 - val_loss: 1.9948 - val_acc: 0.5174\n",
            "Epoch 63/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.4734 - acc: 0.8307 - val_loss: 1.8469 - val_acc: 0.5288\n",
            "Epoch 64/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.4715 - acc: 0.8319 - val_loss: 1.9365 - val_acc: 0.5323\n",
            "Epoch 65/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.4662 - acc: 0.8331 - val_loss: 1.9357 - val_acc: 0.5229\n",
            "Epoch 66/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.4394 - acc: 0.8424 - val_loss: 2.0072 - val_acc: 0.5252\n",
            "Epoch 67/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.4453 - acc: 0.8403 - val_loss: 1.9100 - val_acc: 0.5370\n",
            "Epoch 68/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.4069 - acc: 0.8539 - val_loss: 1.9499 - val_acc: 0.5333\n",
            "Epoch 69/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.4236 - acc: 0.8481 - val_loss: 2.0425 - val_acc: 0.5264\n",
            "Epoch 70/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.4150 - acc: 0.8505 - val_loss: 2.0702 - val_acc: 0.5276\n",
            "Epoch 71/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.3975 - acc: 0.8589 - val_loss: 2.0599 - val_acc: 0.5358\n",
            "Epoch 72/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.3886 - acc: 0.8614 - val_loss: 2.0798 - val_acc: 0.5302\n",
            "Epoch 73/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.3937 - acc: 0.8579 - val_loss: 2.1152 - val_acc: 0.5210\n",
            "Epoch 74/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.3819 - acc: 0.8626 - val_loss: 2.1072 - val_acc: 0.5311\n",
            "Epoch 75/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.3476 - acc: 0.8771 - val_loss: 2.0728 - val_acc: 0.5217\n",
            "Epoch 76/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.3469 - acc: 0.8752 - val_loss: 2.2030 - val_acc: 0.5335\n",
            "Epoch 77/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.3274 - acc: 0.8833 - val_loss: 2.3233 - val_acc: 0.5098\n",
            "Epoch 78/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.3397 - acc: 0.8790 - val_loss: 2.2394 - val_acc: 0.5301\n",
            "Epoch 79/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.3197 - acc: 0.8856 - val_loss: 2.2412 - val_acc: 0.5265\n",
            "Epoch 80/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.3273 - acc: 0.8836 - val_loss: 2.3515 - val_acc: 0.5180\n",
            "Epoch 81/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.3172 - acc: 0.8872 - val_loss: 2.3572 - val_acc: 0.5235\n",
            "Epoch 82/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2835 - acc: 0.8989 - val_loss: 2.3118 - val_acc: 0.5408\n",
            "Epoch 83/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.2883 - acc: 0.8959 - val_loss: 2.5024 - val_acc: 0.5259\n",
            "Epoch 84/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.2745 - acc: 0.9034 - val_loss: 2.5315 - val_acc: 0.5175\n",
            "Epoch 85/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.2961 - acc: 0.8946 - val_loss: 2.4543 - val_acc: 0.5207\n",
            "Epoch 86/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.2474 - acc: 0.9117 - val_loss: 2.4760 - val_acc: 0.5230\n",
            "Epoch 87/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2643 - acc: 0.9064 - val_loss: 2.6255 - val_acc: 0.5009\n",
            "Epoch 88/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2770 - acc: 0.9017 - val_loss: 2.5293 - val_acc: 0.5250\n",
            "Epoch 89/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2635 - acc: 0.9052 - val_loss: 2.5111 - val_acc: 0.5288\n",
            "Epoch 90/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2566 - acc: 0.9086 - val_loss: 2.5522 - val_acc: 0.5260\n",
            "Epoch 91/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2441 - acc: 0.9130 - val_loss: 2.4550 - val_acc: 0.5296\n",
            "Epoch 92/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2341 - acc: 0.9167 - val_loss: 2.5946 - val_acc: 0.5364\n",
            "Epoch 93/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2259 - acc: 0.9192 - val_loss: 2.6383 - val_acc: 0.5313\n",
            "Epoch 94/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.2276 - acc: 0.9185 - val_loss: 2.5224 - val_acc: 0.5304\n",
            "Epoch 95/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2043 - acc: 0.9275 - val_loss: 2.6689 - val_acc: 0.5279\n",
            "Epoch 96/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2441 - acc: 0.9115 - val_loss: 2.5742 - val_acc: 0.5356\n",
            "Epoch 97/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.1983 - acc: 0.9296 - val_loss: 2.6268 - val_acc: 0.5366\n",
            "Epoch 98/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.1847 - acc: 0.9335 - val_loss: 2.7093 - val_acc: 0.5344\n",
            "Epoch 99/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.1769 - acc: 0.9384 - val_loss: 2.7238 - val_acc: 0.5385\n",
            "Epoch 100/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.1843 - acc: 0.9350 - val_loss: 2.9920 - val_acc: 0.5095\n",
            "Epoch 101/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2221 - acc: 0.9204 - val_loss: 2.7643 - val_acc: 0.5281\n",
            "Epoch 102/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.1885 - acc: 0.9326 - val_loss: 2.7821 - val_acc: 0.5246\n",
            "Epoch 103/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.1947 - acc: 0.9311 - val_loss: 2.8206 - val_acc: 0.5328\n",
            "Epoch 104/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.1545 - acc: 0.9469 - val_loss: 2.8601 - val_acc: 0.5345\n",
            "Epoch 105/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.1687 - acc: 0.9405 - val_loss: 2.8184 - val_acc: 0.5316\n",
            "Epoch 106/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.1527 - acc: 0.9460 - val_loss: 2.8633 - val_acc: 0.5341\n",
            "Epoch 107/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.1813 - acc: 0.9351 - val_loss: 3.1216 - val_acc: 0.5105\n",
            "Epoch 108/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2521 - acc: 0.9105 - val_loss: 2.9540 - val_acc: 0.5272\n",
            "Epoch 109/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.1689 - acc: 0.9408 - val_loss: 2.9559 - val_acc: 0.5266\n",
            "Epoch 110/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.1670 - acc: 0.9411 - val_loss: 2.9028 - val_acc: 0.5254\n",
            "Epoch 111/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 0.1681 - acc: 0.9403 - val_loss: 3.0880 - val_acc: 0.5114\n",
            "Epoch 112/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.1556 - acc: 0.9442 - val_loss: 3.1369 - val_acc: 0.5120\n",
            "Epoch 113/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.1672 - acc: 0.9409 - val_loss: 3.0619 - val_acc: 0.5313\n",
            "Epoch 114/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.1303 - acc: 0.9544 - val_loss: 3.0656 - val_acc: 0.5374\n",
            "Epoch 115/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 0.1261 - acc: 0.9562 - val_loss: 3.1873 - val_acc: 0.5322\n",
            "Epoch 116/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.1363 - acc: 0.9507 - val_loss: 3.0969 - val_acc: 0.5359\n",
            "Epoch 117/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.1018 - acc: 0.9646 - val_loss: 3.1486 - val_acc: 0.5248\n",
            "Epoch 118/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 0.1463 - acc: 0.9481 - val_loss: 3.0898 - val_acc: 0.5264\n",
            "Epoch 119/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.1534 - acc: 0.9455 - val_loss: 3.2298 - val_acc: 0.5223\n",
            "Epoch 120/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.1484 - acc: 0.9468 - val_loss: 3.0532 - val_acc: 0.5432\n",
            "Epoch 121/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 0.1157 - acc: 0.9598 - val_loss: 3.2158 - val_acc: 0.5276\n",
            "Epoch 122/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.1783 - acc: 0.9372 - val_loss: 3.1174 - val_acc: 0.5312\n",
            "Epoch 123/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.1392 - acc: 0.9515 - val_loss: 3.0777 - val_acc: 0.5346\n",
            "Epoch 124/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.0871 - acc: 0.9711 - val_loss: 3.2582 - val_acc: 0.5334\n",
            "Epoch 125/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.1578 - acc: 0.9436 - val_loss: 3.2361 - val_acc: 0.5227\n",
            "Epoch 126/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.0932 - acc: 0.9676 - val_loss: 3.3152 - val_acc: 0.5252\n",
            "Epoch 127/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.1212 - acc: 0.9573 - val_loss: 3.2074 - val_acc: 0.5389\n",
            "Epoch 128/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.0718 - acc: 0.9765 - val_loss: 3.2220 - val_acc: 0.5346\n",
            "Epoch 129/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.0695 - acc: 0.9762 - val_loss: 3.3040 - val_acc: 0.5208\n",
            "Epoch 130/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.1171 - acc: 0.9598 - val_loss: 3.4252 - val_acc: 0.5251\n",
            "Epoch 131/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.1376 - acc: 0.9518 - val_loss: 3.2840 - val_acc: 0.5278\n",
            "Epoch 132/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.1577 - acc: 0.9452 - val_loss: 3.4234 - val_acc: 0.5154\n",
            "Epoch 133/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.0760 - acc: 0.9740 - val_loss: 3.3094 - val_acc: 0.5381\n",
            "Epoch 134/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 0.0396 - acc: 0.9885 - val_loss: 3.3804 - val_acc: 0.5408\n",
            "Epoch 135/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.0544 - acc: 0.9824 - val_loss: 3.3514 - val_acc: 0.5431\n",
            "Epoch 136/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.0715 - acc: 0.9756 - val_loss: 3.4307 - val_acc: 0.5251\n",
            "Epoch 137/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 0.1077 - acc: 0.9619 - val_loss: 3.3868 - val_acc: 0.5271\n",
            "Epoch 138/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 0.1659 - acc: 0.9416 - val_loss: 3.4075 - val_acc: 0.5197\n",
            "Epoch 139/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.2054 - acc: 0.9276 - val_loss: 3.3504 - val_acc: 0.5230\n",
            "Epoch 140/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.1328 - acc: 0.9527 - val_loss: 3.2396 - val_acc: 0.5316\n",
            "Epoch 141/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.0725 - acc: 0.9758 - val_loss: 3.5008 - val_acc: 0.5334\n",
            "Epoch 142/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.0517 - acc: 0.9828 - val_loss: 3.3657 - val_acc: 0.5413\n",
            "Epoch 143/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.0256 - acc: 0.9929 - val_loss: 3.4418 - val_acc: 0.5373\n",
            "Epoch 144/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.0201 - acc: 0.9948 - val_loss: 3.4481 - val_acc: 0.5441\n",
            "Epoch 145/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.0145 - acc: 0.9966 - val_loss: 3.5177 - val_acc: 0.5470\n",
            "Epoch 146/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.0141 - acc: 0.9970 - val_loss: 3.4888 - val_acc: 0.5513\n",
            "Epoch 147/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.0126 - acc: 0.9968 - val_loss: 3.5430 - val_acc: 0.5450\n",
            "Epoch 148/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.0114 - acc: 0.9975 - val_loss: 3.5655 - val_acc: 0.5486\n",
            "Epoch 149/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.0098 - acc: 0.9979 - val_loss: 3.5625 - val_acc: 0.5445\n",
            "Epoch 150/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.0102 - acc: 0.9979 - val_loss: 3.5902 - val_acc: 0.5526\n",
            "Epoch 151/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.0068 - acc: 0.9988 - val_loss: 3.6416 - val_acc: 0.5503\n",
            "Epoch 152/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.0089 - acc: 0.9983 - val_loss: 3.6022 - val_acc: 0.5467\n",
            "Epoch 153/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.0060 - acc: 0.9990 - val_loss: 3.6698 - val_acc: 0.5455\n",
            "Epoch 154/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.0048 - acc: 0.9994 - val_loss: 3.6909 - val_acc: 0.5511\n",
            "Epoch 155/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.0056 - acc: 0.9991 - val_loss: 3.6864 - val_acc: 0.5451\n",
            "Epoch 156/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 0.0038 - acc: 0.9996 - val_loss: 3.6899 - val_acc: 0.5469\n",
            "Epoch 157/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.0042 - acc: 0.9994 - val_loss: 3.7154 - val_acc: 0.5502\n",
            "Epoch 158/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.0032 - acc: 0.9997 - val_loss: 3.7182 - val_acc: 0.5473\n",
            "Epoch 159/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 0.0032 - acc: 0.9997 - val_loss: 3.7483 - val_acc: 0.5506\n",
            "Epoch 160/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 0.0023 - acc: 0.9998 - val_loss: 3.7665 - val_acc: 0.5522\n",
            "Epoch 161/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 0.0022 - acc: 0.9999 - val_loss: 3.7717 - val_acc: 0.5515\n",
            "Epoch 162/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 0.0021 - acc: 0.9999 - val_loss: 3.7928 - val_acc: 0.5450\n",
            "Epoch 163/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 0.0025 - acc: 0.9997 - val_loss: 3.7724 - val_acc: 0.5489\n",
            "Epoch 164/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.0038 - acc: 0.9994 - val_loss: 3.7974 - val_acc: 0.5504\n",
            "Epoch 165/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.0020 - acc: 0.9998 - val_loss: 3.8181 - val_acc: 0.5497\n",
            "Epoch 166/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 0.0017 - acc: 0.9999 - val_loss: 3.8155 - val_acc: 0.5494\n",
            "Epoch 167/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 0.0014 - acc: 0.9999 - val_loss: 3.8323 - val_acc: 0.5524\n",
            "Epoch 168/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 3.8423 - val_acc: 0.5518\n",
            "Epoch 169/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 3.8386 - val_acc: 0.5515\n",
            "Epoch 170/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 0.0012 - acc: 0.9999 - val_loss: 3.8511 - val_acc: 0.5518\n",
            "Epoch 171/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 3.8515 - val_acc: 0.5500\n",
            "Epoch 172/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.0021 - acc: 0.9998 - val_loss: 3.8457 - val_acc: 0.5512\n",
            "Epoch 173/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 3.8613 - val_acc: 0.5504\n",
            "Epoch 174/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 9.4194e-04 - acc: 1.0000 - val_loss: 3.8718 - val_acc: 0.5528\n",
            "Epoch 175/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 0.0013 - acc: 0.9999 - val_loss: 3.8720 - val_acc: 0.5523\n",
            "Epoch 176/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 8.4914e-04 - acc: 1.0000 - val_loss: 3.8838 - val_acc: 0.5513\n",
            "Epoch 177/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 8.1978e-04 - acc: 1.0000 - val_loss: 3.8849 - val_acc: 0.5534\n",
            "Epoch 178/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 7.8349e-04 - acc: 1.0000 - val_loss: 3.9033 - val_acc: 0.5513\n",
            "Epoch 179/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 7.5670e-04 - acc: 1.0000 - val_loss: 3.9055 - val_acc: 0.5528\n",
            "Epoch 180/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 7.4227e-04 - acc: 1.0000 - val_loss: 3.9038 - val_acc: 0.5533\n",
            "Epoch 181/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 7.1117e-04 - acc: 1.0000 - val_loss: 3.9136 - val_acc: 0.5518\n",
            "Epoch 182/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 7.0661e-04 - acc: 1.0000 - val_loss: 3.9156 - val_acc: 0.5525\n",
            "Epoch 183/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 6.7683e-04 - acc: 1.0000 - val_loss: 3.9234 - val_acc: 0.5501\n",
            "Epoch 184/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 6.5534e-04 - acc: 1.0000 - val_loss: 3.9289 - val_acc: 0.5523\n",
            "Epoch 185/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 6.6004e-04 - acc: 1.0000 - val_loss: 3.9351 - val_acc: 0.5515\n",
            "Epoch 186/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 6.2527e-04 - acc: 1.0000 - val_loss: 3.9324 - val_acc: 0.5513\n",
            "Epoch 187/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 6.3032e-04 - acc: 1.0000 - val_loss: 3.9387 - val_acc: 0.5518\n",
            "Epoch 188/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 6.1879e-04 - acc: 1.0000 - val_loss: 3.9442 - val_acc: 0.5524\n",
            "Epoch 189/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 5.9077e-04 - acc: 1.0000 - val_loss: 3.9490 - val_acc: 0.5514\n",
            "Epoch 190/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 5.9041e-04 - acc: 1.0000 - val_loss: 3.9525 - val_acc: 0.5508\n",
            "Epoch 191/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 5.6915e-04 - acc: 1.0000 - val_loss: 3.9505 - val_acc: 0.5534\n",
            "Epoch 192/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 5.5835e-04 - acc: 1.0000 - val_loss: 3.9584 - val_acc: 0.5503\n",
            "Epoch 193/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 5.4872e-04 - acc: 1.0000 - val_loss: 3.9579 - val_acc: 0.5528\n",
            "Epoch 194/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 5.3836e-04 - acc: 1.0000 - val_loss: 3.9619 - val_acc: 0.5510\n",
            "Epoch 195/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 5.3487e-04 - acc: 1.0000 - val_loss: 3.9632 - val_acc: 0.5538\n",
            "Epoch 196/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 5.1828e-04 - acc: 1.0000 - val_loss: 3.9702 - val_acc: 0.5523\n",
            "Epoch 197/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 5.0476e-04 - acc: 1.0000 - val_loss: 3.9756 - val_acc: 0.5532\n",
            "Epoch 198/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 5.0569e-04 - acc: 1.0000 - val_loss: 3.9773 - val_acc: 0.5516\n",
            "Epoch 199/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 4.8906e-04 - acc: 1.0000 - val_loss: 3.9829 - val_acc: 0.5522\n",
            "Epoch 200/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 4.8744e-04 - acc: 1.0000 - val_loss: 3.9858 - val_acc: 0.5521\n",
            "Epoch 201/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 4.7689e-04 - acc: 1.0000 - val_loss: 3.9879 - val_acc: 0.5528\n",
            "Epoch 202/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 4.6624e-04 - acc: 1.0000 - val_loss: 3.9907 - val_acc: 0.5524\n",
            "Epoch 203/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 4.6206e-04 - acc: 1.0000 - val_loss: 3.9917 - val_acc: 0.5522\n",
            "Epoch 204/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 4.5412e-04 - acc: 1.0000 - val_loss: 3.9919 - val_acc: 0.5517\n",
            "Epoch 205/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 4.4672e-04 - acc: 1.0000 - val_loss: 3.9986 - val_acc: 0.5520\n",
            "Epoch 206/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 4.4208e-04 - acc: 1.0000 - val_loss: 3.9992 - val_acc: 0.5515\n",
            "Epoch 207/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 4.3088e-04 - acc: 1.0000 - val_loss: 4.0050 - val_acc: 0.5517\n",
            "Epoch 208/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 4.2762e-04 - acc: 1.0000 - val_loss: 4.0060 - val_acc: 0.5518\n",
            "Epoch 209/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 4.2080e-04 - acc: 1.0000 - val_loss: 4.0089 - val_acc: 0.5521\n",
            "Epoch 210/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 4.1529e-04 - acc: 1.0000 - val_loss: 4.0097 - val_acc: 0.5534\n",
            "Epoch 211/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 4.1118e-04 - acc: 1.0000 - val_loss: 4.0134 - val_acc: 0.5518\n",
            "Epoch 212/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 4.0405e-04 - acc: 1.0000 - val_loss: 4.0171 - val_acc: 0.5514\n",
            "Epoch 213/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 4.0016e-04 - acc: 1.0000 - val_loss: 4.0192 - val_acc: 0.5535\n",
            "Epoch 214/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 3.9193e-04 - acc: 1.0000 - val_loss: 4.0181 - val_acc: 0.5526\n",
            "Epoch 215/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 3.8978e-04 - acc: 1.0000 - val_loss: 4.0256 - val_acc: 0.5523\n",
            "Epoch 216/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 3.8618e-04 - acc: 1.0000 - val_loss: 4.0280 - val_acc: 0.5522\n",
            "Epoch 217/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 3.7751e-04 - acc: 1.0000 - val_loss: 4.0293 - val_acc: 0.5521\n",
            "Epoch 218/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 3.7429e-04 - acc: 1.0000 - val_loss: 4.0328 - val_acc: 0.5527\n",
            "Epoch 219/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 3.6990e-04 - acc: 1.0000 - val_loss: 4.0359 - val_acc: 0.5517\n",
            "Epoch 220/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 3.6452e-04 - acc: 1.0000 - val_loss: 4.0382 - val_acc: 0.5523\n",
            "Epoch 221/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 3.6179e-04 - acc: 1.0000 - val_loss: 4.0374 - val_acc: 0.5521\n",
            "Epoch 222/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 3.5747e-04 - acc: 1.0000 - val_loss: 4.0400 - val_acc: 0.5524\n",
            "Epoch 223/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 3.5234e-04 - acc: 1.0000 - val_loss: 4.0438 - val_acc: 0.5517\n",
            "Epoch 224/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 3.4858e-04 - acc: 1.0000 - val_loss: 4.0441 - val_acc: 0.5536\n",
            "Epoch 225/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 3.4409e-04 - acc: 1.0000 - val_loss: 4.0460 - val_acc: 0.5516\n",
            "Epoch 226/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 3.4160e-04 - acc: 1.0000 - val_loss: 4.0501 - val_acc: 0.5519\n",
            "Epoch 227/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 3.3759e-04 - acc: 1.0000 - val_loss: 4.0525 - val_acc: 0.5523\n",
            "Epoch 228/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 3.3474e-04 - acc: 1.0000 - val_loss: 4.0560 - val_acc: 0.5526\n",
            "Epoch 229/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 3.2841e-04 - acc: 1.0000 - val_loss: 4.0568 - val_acc: 0.5525\n",
            "Epoch 230/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 3.2547e-04 - acc: 1.0000 - val_loss: 4.0600 - val_acc: 0.5523\n",
            "Epoch 231/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 3.2169e-04 - acc: 1.0000 - val_loss: 4.0606 - val_acc: 0.5534\n",
            "Epoch 232/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 3.1824e-04 - acc: 1.0000 - val_loss: 4.0629 - val_acc: 0.5510\n",
            "Epoch 233/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 3.1581e-04 - acc: 1.0000 - val_loss: 4.0657 - val_acc: 0.5524\n",
            "Epoch 234/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 3.1413e-04 - acc: 1.0000 - val_loss: 4.0656 - val_acc: 0.5525\n",
            "Epoch 235/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 3.1100e-04 - acc: 1.0000 - val_loss: 4.0682 - val_acc: 0.5514\n",
            "Epoch 236/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 3.0664e-04 - acc: 1.0000 - val_loss: 4.0720 - val_acc: 0.5520\n",
            "Epoch 237/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 3.0270e-04 - acc: 1.0000 - val_loss: 4.0728 - val_acc: 0.5527\n",
            "Epoch 238/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 3.0043e-04 - acc: 1.0000 - val_loss: 4.0745 - val_acc: 0.5533\n",
            "Epoch 239/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 2.9673e-04 - acc: 1.0000 - val_loss: 4.0767 - val_acc: 0.5521\n",
            "Epoch 240/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 2.9356e-04 - acc: 1.0000 - val_loss: 4.0780 - val_acc: 0.5528\n",
            "Epoch 241/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 2.9047e-04 - acc: 1.0000 - val_loss: 4.0789 - val_acc: 0.5522\n",
            "Epoch 242/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 2.8818e-04 - acc: 1.0000 - val_loss: 4.0817 - val_acc: 0.5514\n",
            "Epoch 243/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 2.8651e-04 - acc: 1.0000 - val_loss: 4.0819 - val_acc: 0.5524\n",
            "Epoch 244/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 2.8565e-04 - acc: 1.0000 - val_loss: 4.0833 - val_acc: 0.5526\n",
            "Epoch 245/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 2.8319e-04 - acc: 1.0000 - val_loss: 4.0861 - val_acc: 0.5520\n",
            "Epoch 246/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 2.8086e-04 - acc: 1.0000 - val_loss: 4.0875 - val_acc: 0.5521\n",
            "Epoch 247/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 2.7498e-04 - acc: 1.0000 - val_loss: 4.0913 - val_acc: 0.5523\n",
            "Epoch 248/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 2.7272e-04 - acc: 1.0000 - val_loss: 4.0900 - val_acc: 0.5529\n",
            "Epoch 249/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 2.7036e-04 - acc: 1.0000 - val_loss: 4.0945 - val_acc: 0.5517\n",
            "Epoch 250/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 2.6913e-04 - acc: 1.0000 - val_loss: 4.0943 - val_acc: 0.5529\n",
            "Epoch 251/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 2.6545e-04 - acc: 1.0000 - val_loss: 4.0961 - val_acc: 0.5524\n",
            "Epoch 252/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 2.6376e-04 - acc: 1.0000 - val_loss: 4.1003 - val_acc: 0.5513\n",
            "Epoch 253/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 2.6106e-04 - acc: 1.0000 - val_loss: 4.1006 - val_acc: 0.5529\n",
            "Epoch 254/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 2.5869e-04 - acc: 1.0000 - val_loss: 4.1016 - val_acc: 0.5530\n",
            "Epoch 255/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 2.5738e-04 - acc: 1.0000 - val_loss: 4.1072 - val_acc: 0.5530\n",
            "Epoch 256/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 2.5425e-04 - acc: 1.0000 - val_loss: 4.1050 - val_acc: 0.5523\n",
            "Epoch 257/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 2.5239e-04 - acc: 1.0000 - val_loss: 4.1072 - val_acc: 0.5521\n",
            "Epoch 258/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 2.5039e-04 - acc: 1.0000 - val_loss: 4.1081 - val_acc: 0.5523\n",
            "Epoch 259/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 2.4841e-04 - acc: 1.0000 - val_loss: 4.1111 - val_acc: 0.5527\n",
            "Epoch 260/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 2.4589e-04 - acc: 1.0000 - val_loss: 4.1096 - val_acc: 0.5530\n",
            "Epoch 261/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 2.4383e-04 - acc: 1.0000 - val_loss: 4.1137 - val_acc: 0.5522\n",
            "Epoch 262/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 2.4195e-04 - acc: 1.0000 - val_loss: 4.1146 - val_acc: 0.5527\n",
            "Epoch 263/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 2.4039e-04 - acc: 1.0000 - val_loss: 4.1157 - val_acc: 0.5535\n",
            "Epoch 264/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 2.3905e-04 - acc: 1.0000 - val_loss: 4.1171 - val_acc: 0.5527\n",
            "Epoch 265/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 2.3709e-04 - acc: 1.0000 - val_loss: 4.1206 - val_acc: 0.5527\n",
            "Epoch 266/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 2.3510e-04 - acc: 1.0000 - val_loss: 4.1191 - val_acc: 0.5523\n",
            "Epoch 267/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 2.3351e-04 - acc: 1.0000 - val_loss: 4.1215 - val_acc: 0.5527\n",
            "Epoch 268/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 2.3196e-04 - acc: 1.0000 - val_loss: 4.1230 - val_acc: 0.5522\n",
            "Epoch 269/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 2.2854e-04 - acc: 1.0000 - val_loss: 4.1239 - val_acc: 0.5531\n",
            "Epoch 270/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 2.2835e-04 - acc: 1.0000 - val_loss: 4.1265 - val_acc: 0.5519\n",
            "Epoch 271/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 2.2618e-04 - acc: 1.0000 - val_loss: 4.1279 - val_acc: 0.5519\n",
            "Epoch 272/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 2.2522e-04 - acc: 1.0000 - val_loss: 4.1304 - val_acc: 0.5526\n",
            "Epoch 273/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 2.2328e-04 - acc: 1.0000 - val_loss: 4.1302 - val_acc: 0.5528\n",
            "Epoch 274/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 2.2205e-04 - acc: 1.0000 - val_loss: 4.1313 - val_acc: 0.5529\n",
            "Epoch 275/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 2.2010e-04 - acc: 1.0000 - val_loss: 4.1327 - val_acc: 0.5524\n",
            "Epoch 276/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 2.1829e-04 - acc: 1.0000 - val_loss: 4.1347 - val_acc: 0.5524\n",
            "Epoch 277/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 2.1646e-04 - acc: 1.0000 - val_loss: 4.1379 - val_acc: 0.5521\n",
            "Epoch 278/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 2.1628e-04 - acc: 1.0000 - val_loss: 4.1380 - val_acc: 0.5525\n",
            "Epoch 279/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 2.1283e-04 - acc: 1.0000 - val_loss: 4.1413 - val_acc: 0.5531\n",
            "Epoch 280/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 2.1223e-04 - acc: 1.0000 - val_loss: 4.1409 - val_acc: 0.5530\n",
            "Epoch 281/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 2.1076e-04 - acc: 1.0000 - val_loss: 4.1419 - val_acc: 0.5529\n",
            "Epoch 282/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 2.0964e-04 - acc: 1.0000 - val_loss: 4.1429 - val_acc: 0.5525\n",
            "Epoch 283/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 2.0801e-04 - acc: 1.0000 - val_loss: 4.1443 - val_acc: 0.5525\n",
            "Epoch 284/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 2.0649e-04 - acc: 1.0000 - val_loss: 4.1468 - val_acc: 0.5525\n",
            "Epoch 285/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 2.0495e-04 - acc: 1.0000 - val_loss: 4.1472 - val_acc: 0.5519\n",
            "Epoch 286/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 2.0323e-04 - acc: 1.0000 - val_loss: 4.1472 - val_acc: 0.5529\n",
            "Epoch 287/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 2.0162e-04 - acc: 1.0000 - val_loss: 4.1501 - val_acc: 0.5523\n",
            "Epoch 288/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 2.0035e-04 - acc: 1.0000 - val_loss: 4.1506 - val_acc: 0.5527\n",
            "Epoch 289/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.9979e-04 - acc: 1.0000 - val_loss: 4.1503 - val_acc: 0.5526\n",
            "Epoch 290/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.9801e-04 - acc: 1.0000 - val_loss: 4.1527 - val_acc: 0.5533\n",
            "Epoch 291/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.9740e-04 - acc: 1.0000 - val_loss: 4.1561 - val_acc: 0.5529\n",
            "Epoch 292/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.9532e-04 - acc: 1.0000 - val_loss: 4.1560 - val_acc: 0.5534\n",
            "Epoch 293/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.9443e-04 - acc: 1.0000 - val_loss: 4.1585 - val_acc: 0.5523\n",
            "Epoch 294/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.9320e-04 - acc: 1.0000 - val_loss: 4.1582 - val_acc: 0.5522\n",
            "Epoch 295/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.9150e-04 - acc: 1.0000 - val_loss: 4.1595 - val_acc: 0.5526\n",
            "Epoch 296/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.9046e-04 - acc: 1.0000 - val_loss: 4.1627 - val_acc: 0.5522\n",
            "Epoch 297/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.8948e-04 - acc: 1.0000 - val_loss: 4.1604 - val_acc: 0.5534\n",
            "Epoch 298/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.8803e-04 - acc: 1.0000 - val_loss: 4.1640 - val_acc: 0.5524\n",
            "Epoch 299/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.8727e-04 - acc: 1.0000 - val_loss: 4.1655 - val_acc: 0.5529\n",
            "Epoch 300/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.8551e-04 - acc: 1.0000 - val_loss: 4.1656 - val_acc: 0.5529\n",
            "Epoch 301/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.8452e-04 - acc: 1.0000 - val_loss: 4.1670 - val_acc: 0.5521\n",
            "Epoch 302/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.8333e-04 - acc: 1.0000 - val_loss: 4.1688 - val_acc: 0.5532\n",
            "Epoch 303/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.8261e-04 - acc: 1.0000 - val_loss: 4.1697 - val_acc: 0.5526\n",
            "Epoch 304/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.8107e-04 - acc: 1.0000 - val_loss: 4.1700 - val_acc: 0.5523\n",
            "Epoch 305/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.8047e-04 - acc: 1.0000 - val_loss: 4.1718 - val_acc: 0.5527\n",
            "Epoch 306/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.7884e-04 - acc: 1.0000 - val_loss: 4.1732 - val_acc: 0.5525\n",
            "Epoch 307/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.7820e-04 - acc: 1.0000 - val_loss: 4.1737 - val_acc: 0.5529\n",
            "Epoch 308/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.7685e-04 - acc: 1.0000 - val_loss: 4.1750 - val_acc: 0.5519\n",
            "Epoch 309/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.7569e-04 - acc: 1.0000 - val_loss: 4.1783 - val_acc: 0.5530\n",
            "Epoch 310/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.7526e-04 - acc: 1.0000 - val_loss: 4.1768 - val_acc: 0.5525\n",
            "Epoch 311/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.7373e-04 - acc: 1.0000 - val_loss: 4.1795 - val_acc: 0.5530\n",
            "Epoch 312/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.7297e-04 - acc: 1.0000 - val_loss: 4.1798 - val_acc: 0.5520\n",
            "Epoch 313/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.7226e-04 - acc: 1.0000 - val_loss: 4.1815 - val_acc: 0.5530\n",
            "Epoch 314/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.7113e-04 - acc: 1.0000 - val_loss: 4.1827 - val_acc: 0.5523\n",
            "Epoch 315/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.7039e-04 - acc: 1.0000 - val_loss: 4.1835 - val_acc: 0.5535\n",
            "Epoch 316/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.6897e-04 - acc: 1.0000 - val_loss: 4.1846 - val_acc: 0.5523\n",
            "Epoch 317/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.6817e-04 - acc: 1.0000 - val_loss: 4.1862 - val_acc: 0.5524\n",
            "Epoch 318/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.6709e-04 - acc: 1.0000 - val_loss: 4.1871 - val_acc: 0.5523\n",
            "Epoch 319/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.6626e-04 - acc: 1.0000 - val_loss: 4.1883 - val_acc: 0.5526\n",
            "Epoch 320/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.6511e-04 - acc: 1.0000 - val_loss: 4.1887 - val_acc: 0.5523\n",
            "Epoch 321/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.6449e-04 - acc: 1.0000 - val_loss: 4.1897 - val_acc: 0.5525\n",
            "Epoch 322/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.6362e-04 - acc: 1.0000 - val_loss: 4.1910 - val_acc: 0.5530\n",
            "Epoch 323/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.6250e-04 - acc: 1.0000 - val_loss: 4.1922 - val_acc: 0.5530\n",
            "Epoch 324/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.6151e-04 - acc: 1.0000 - val_loss: 4.1929 - val_acc: 0.5530\n",
            "Epoch 325/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.6076e-04 - acc: 1.0000 - val_loss: 4.1924 - val_acc: 0.5524\n",
            "Epoch 326/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.5999e-04 - acc: 1.0000 - val_loss: 4.1957 - val_acc: 0.5526\n",
            "Epoch 327/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.5896e-04 - acc: 1.0000 - val_loss: 4.1963 - val_acc: 0.5526\n",
            "Epoch 328/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.5821e-04 - acc: 1.0000 - val_loss: 4.1971 - val_acc: 0.5527\n",
            "Epoch 329/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.5752e-04 - acc: 1.0000 - val_loss: 4.1974 - val_acc: 0.5525\n",
            "Epoch 330/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.5641e-04 - acc: 1.0000 - val_loss: 4.1985 - val_acc: 0.5524\n",
            "Epoch 331/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.5574e-04 - acc: 1.0000 - val_loss: 4.2003 - val_acc: 0.5522\n",
            "Epoch 332/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.5459e-04 - acc: 1.0000 - val_loss: 4.2008 - val_acc: 0.5529\n",
            "Epoch 333/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.5401e-04 - acc: 1.0000 - val_loss: 4.2026 - val_acc: 0.5518\n",
            "Epoch 334/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.5310e-04 - acc: 1.0000 - val_loss: 4.2023 - val_acc: 0.5529\n",
            "Epoch 335/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 1.5305e-04 - acc: 1.0000 - val_loss: 4.2040 - val_acc: 0.5522\n",
            "Epoch 336/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.5209e-04 - acc: 1.0000 - val_loss: 4.2042 - val_acc: 0.5528\n",
            "Epoch 337/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 1.5100e-04 - acc: 1.0000 - val_loss: 4.2064 - val_acc: 0.5518\n",
            "Epoch 338/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.5006e-04 - acc: 1.0000 - val_loss: 4.2081 - val_acc: 0.5528\n",
            "Epoch 339/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.4988e-04 - acc: 1.0000 - val_loss: 4.2096 - val_acc: 0.5530\n",
            "Epoch 340/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.4875e-04 - acc: 1.0000 - val_loss: 4.2088 - val_acc: 0.5530\n",
            "Epoch 341/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.4832e-04 - acc: 1.0000 - val_loss: 4.2108 - val_acc: 0.5518\n",
            "Epoch 342/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.4713e-04 - acc: 1.0000 - val_loss: 4.2121 - val_acc: 0.5522\n",
            "Epoch 343/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.4656e-04 - acc: 1.0000 - val_loss: 4.2124 - val_acc: 0.5533\n",
            "Epoch 344/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.4574e-04 - acc: 1.0000 - val_loss: 4.2135 - val_acc: 0.5527\n",
            "Epoch 345/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.4503e-04 - acc: 1.0000 - val_loss: 4.2145 - val_acc: 0.5523\n",
            "Epoch 346/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.4420e-04 - acc: 1.0000 - val_loss: 4.2162 - val_acc: 0.5523\n",
            "Epoch 347/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 1.4365e-04 - acc: 1.0000 - val_loss: 4.2166 - val_acc: 0.5524\n",
            "Epoch 348/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.4318e-04 - acc: 1.0000 - val_loss: 4.2173 - val_acc: 0.5523\n",
            "Epoch 349/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.4233e-04 - acc: 1.0000 - val_loss: 4.2187 - val_acc: 0.5521\n",
            "Epoch 350/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.4114e-04 - acc: 1.0000 - val_loss: 4.2188 - val_acc: 0.5529\n",
            "Epoch 351/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 1.4097e-04 - acc: 1.0000 - val_loss: 4.2201 - val_acc: 0.5532\n",
            "Epoch 352/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.4020e-04 - acc: 1.0000 - val_loss: 4.2197 - val_acc: 0.5522\n",
            "Epoch 353/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.3933e-04 - acc: 1.0000 - val_loss: 4.2232 - val_acc: 0.5521\n",
            "Epoch 354/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.3872e-04 - acc: 1.0000 - val_loss: 4.2236 - val_acc: 0.5530\n",
            "Epoch 355/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.3825e-04 - acc: 1.0000 - val_loss: 4.2236 - val_acc: 0.5526\n",
            "Epoch 356/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.3751e-04 - acc: 1.0000 - val_loss: 4.2251 - val_acc: 0.5530\n",
            "Epoch 357/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.3728e-04 - acc: 1.0000 - val_loss: 4.2256 - val_acc: 0.5525\n",
            "Epoch 358/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.3633e-04 - acc: 1.0000 - val_loss: 4.2262 - val_acc: 0.5525\n",
            "Epoch 359/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.3567e-04 - acc: 1.0000 - val_loss: 4.2274 - val_acc: 0.5527\n",
            "Epoch 360/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.3482e-04 - acc: 1.0000 - val_loss: 4.2295 - val_acc: 0.5522\n",
            "Epoch 361/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.3429e-04 - acc: 1.0000 - val_loss: 4.2285 - val_acc: 0.5530\n",
            "Epoch 362/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.3376e-04 - acc: 1.0000 - val_loss: 4.2299 - val_acc: 0.5527\n",
            "Epoch 363/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.3363e-04 - acc: 1.0000 - val_loss: 4.2311 - val_acc: 0.5526\n",
            "Epoch 364/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.3255e-04 - acc: 1.0000 - val_loss: 4.2318 - val_acc: 0.5520\n",
            "Epoch 365/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.3208e-04 - acc: 1.0000 - val_loss: 4.2328 - val_acc: 0.5529\n",
            "Epoch 366/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.3156e-04 - acc: 1.0000 - val_loss: 4.2343 - val_acc: 0.5529\n",
            "Epoch 367/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.3094e-04 - acc: 1.0000 - val_loss: 4.2349 - val_acc: 0.5528\n",
            "Epoch 368/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.3037e-04 - acc: 1.0000 - val_loss: 4.2345 - val_acc: 0.5528\n",
            "Epoch 369/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.2963e-04 - acc: 1.0000 - val_loss: 4.2355 - val_acc: 0.5526\n",
            "Epoch 370/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.2900e-04 - acc: 1.0000 - val_loss: 4.2365 - val_acc: 0.5523\n",
            "Epoch 371/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.2860e-04 - acc: 1.0000 - val_loss: 4.2381 - val_acc: 0.5521\n",
            "Epoch 372/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.2810e-04 - acc: 1.0000 - val_loss: 4.2393 - val_acc: 0.5525\n",
            "Epoch 373/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.2714e-04 - acc: 1.0000 - val_loss: 4.2386 - val_acc: 0.5528\n",
            "Epoch 374/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.2699e-04 - acc: 1.0000 - val_loss: 4.2409 - val_acc: 0.5523\n",
            "Epoch 375/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.2637e-04 - acc: 1.0000 - val_loss: 4.2411 - val_acc: 0.5523\n",
            "Epoch 376/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.2563e-04 - acc: 1.0000 - val_loss: 4.2424 - val_acc: 0.5521\n",
            "Epoch 377/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.2529e-04 - acc: 1.0000 - val_loss: 4.2434 - val_acc: 0.5522\n",
            "Epoch 378/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.2462e-04 - acc: 1.0000 - val_loss: 4.2435 - val_acc: 0.5523\n",
            "Epoch 379/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.2381e-04 - acc: 1.0000 - val_loss: 4.2438 - val_acc: 0.5527\n",
            "Epoch 380/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.2384e-04 - acc: 1.0000 - val_loss: 4.2450 - val_acc: 0.5531\n",
            "Epoch 381/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.2293e-04 - acc: 1.0000 - val_loss: 4.2464 - val_acc: 0.5522\n",
            "Epoch 382/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.2260e-04 - acc: 1.0000 - val_loss: 4.2471 - val_acc: 0.5527\n",
            "Epoch 383/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.2207e-04 - acc: 1.0000 - val_loss: 4.2488 - val_acc: 0.5523\n",
            "Epoch 384/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.2173e-04 - acc: 1.0000 - val_loss: 4.2478 - val_acc: 0.5522\n",
            "Epoch 385/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.2138e-04 - acc: 1.0000 - val_loss: 4.2487 - val_acc: 0.5535\n",
            "Epoch 386/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.2050e-04 - acc: 1.0000 - val_loss: 4.2503 - val_acc: 0.5525\n",
            "Epoch 387/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.2001e-04 - acc: 1.0000 - val_loss: 4.2502 - val_acc: 0.5522\n",
            "Epoch 388/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.1958e-04 - acc: 1.0000 - val_loss: 4.2504 - val_acc: 0.5527\n",
            "Epoch 389/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.1911e-04 - acc: 1.0000 - val_loss: 4.2528 - val_acc: 0.5530\n",
            "Epoch 390/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.1855e-04 - acc: 1.0000 - val_loss: 4.2540 - val_acc: 0.5522\n",
            "Epoch 391/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.1797e-04 - acc: 1.0000 - val_loss: 4.2532 - val_acc: 0.5534\n",
            "Epoch 392/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.1760e-04 - acc: 1.0000 - val_loss: 4.2552 - val_acc: 0.5524\n",
            "Epoch 393/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.1704e-04 - acc: 1.0000 - val_loss: 4.2552 - val_acc: 0.5521\n",
            "Epoch 394/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.1682e-04 - acc: 1.0000 - val_loss: 4.2560 - val_acc: 0.5522\n",
            "Epoch 395/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.1613e-04 - acc: 1.0000 - val_loss: 4.2571 - val_acc: 0.5525\n",
            "Epoch 396/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.1573e-04 - acc: 1.0000 - val_loss: 4.2575 - val_acc: 0.5529\n",
            "Epoch 397/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.1535e-04 - acc: 1.0000 - val_loss: 4.2593 - val_acc: 0.5523\n",
            "Epoch 398/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.1481e-04 - acc: 1.0000 - val_loss: 4.2591 - val_acc: 0.5527\n",
            "Epoch 399/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.1432e-04 - acc: 1.0000 - val_loss: 4.2604 - val_acc: 0.5534\n",
            "Epoch 400/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.1395e-04 - acc: 1.0000 - val_loss: 4.2616 - val_acc: 0.5526\n",
            "Epoch 401/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.1328e-04 - acc: 1.0000 - val_loss: 4.2625 - val_acc: 0.5523\n",
            "Epoch 402/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.1302e-04 - acc: 1.0000 - val_loss: 4.2622 - val_acc: 0.5524\n",
            "Epoch 403/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.1245e-04 - acc: 1.0000 - val_loss: 4.2627 - val_acc: 0.5523\n",
            "Epoch 404/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.1238e-04 - acc: 1.0000 - val_loss: 4.2642 - val_acc: 0.5520\n",
            "Epoch 405/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.1174e-04 - acc: 1.0000 - val_loss: 4.2653 - val_acc: 0.5527\n",
            "Epoch 406/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.1119e-04 - acc: 1.0000 - val_loss: 4.2652 - val_acc: 0.5526\n",
            "Epoch 407/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.1100e-04 - acc: 1.0000 - val_loss: 4.2668 - val_acc: 0.5520\n",
            "Epoch 408/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.1053e-04 - acc: 1.0000 - val_loss: 4.2668 - val_acc: 0.5518\n",
            "Epoch 409/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.1002e-04 - acc: 1.0000 - val_loss: 4.2676 - val_acc: 0.5521\n",
            "Epoch 410/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.0955e-04 - acc: 1.0000 - val_loss: 4.2682 - val_acc: 0.5526\n",
            "Epoch 411/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.0924e-04 - acc: 1.0000 - val_loss: 4.2695 - val_acc: 0.5526\n",
            "Epoch 412/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.0883e-04 - acc: 1.0000 - val_loss: 4.2698 - val_acc: 0.5527\n",
            "Epoch 413/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.0846e-04 - acc: 1.0000 - val_loss: 4.2711 - val_acc: 0.5522\n",
            "Epoch 414/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.0792e-04 - acc: 1.0000 - val_loss: 4.2720 - val_acc: 0.5520\n",
            "Epoch 415/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.0762e-04 - acc: 1.0000 - val_loss: 4.2720 - val_acc: 0.5523\n",
            "Epoch 416/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.0745e-04 - acc: 1.0000 - val_loss: 4.2727 - val_acc: 0.5524\n",
            "Epoch 417/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.0683e-04 - acc: 1.0000 - val_loss: 4.2730 - val_acc: 0.5523\n",
            "Epoch 418/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.0627e-04 - acc: 1.0000 - val_loss: 4.2740 - val_acc: 0.5518\n",
            "Epoch 419/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.0586e-04 - acc: 1.0000 - val_loss: 4.2754 - val_acc: 0.5527\n",
            "Epoch 420/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.0550e-04 - acc: 1.0000 - val_loss: 4.2749 - val_acc: 0.5519\n",
            "Epoch 421/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.0530e-04 - acc: 1.0000 - val_loss: 4.2753 - val_acc: 0.5530\n",
            "Epoch 422/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.0484e-04 - acc: 1.0000 - val_loss: 4.2765 - val_acc: 0.5520\n",
            "Epoch 423/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.0447e-04 - acc: 1.0000 - val_loss: 4.2780 - val_acc: 0.5527\n",
            "Epoch 424/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.0403e-04 - acc: 1.0000 - val_loss: 4.2795 - val_acc: 0.5523\n",
            "Epoch 425/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.0373e-04 - acc: 1.0000 - val_loss: 4.2799 - val_acc: 0.5522\n",
            "Epoch 426/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.0317e-04 - acc: 1.0000 - val_loss: 4.2796 - val_acc: 0.5526\n",
            "Epoch 427/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.0290e-04 - acc: 1.0000 - val_loss: 4.2807 - val_acc: 0.5526\n",
            "Epoch 428/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.0254e-04 - acc: 1.0000 - val_loss: 4.2807 - val_acc: 0.5523\n",
            "Epoch 429/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.0200e-04 - acc: 1.0000 - val_loss: 4.2822 - val_acc: 0.5525\n",
            "Epoch 430/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.0183e-04 - acc: 1.0000 - val_loss: 4.2823 - val_acc: 0.5518\n",
            "Epoch 431/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.0148e-04 - acc: 1.0000 - val_loss: 4.2837 - val_acc: 0.5522\n",
            "Epoch 432/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.0107e-04 - acc: 1.0000 - val_loss: 4.2840 - val_acc: 0.5526\n",
            "Epoch 433/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.0069e-04 - acc: 1.0000 - val_loss: 4.2845 - val_acc: 0.5518\n",
            "Epoch 434/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.0028e-04 - acc: 1.0000 - val_loss: 4.2851 - val_acc: 0.5534\n",
            "Epoch 435/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.0002e-04 - acc: 1.0000 - val_loss: 4.2864 - val_acc: 0.5523\n",
            "Epoch 436/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 9.9586e-05 - acc: 1.0000 - val_loss: 4.2863 - val_acc: 0.5527\n",
            "Epoch 437/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 9.9355e-05 - acc: 1.0000 - val_loss: 4.2868 - val_acc: 0.5523\n",
            "Epoch 438/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 9.8972e-05 - acc: 1.0000 - val_loss: 4.2875 - val_acc: 0.5524\n",
            "Epoch 439/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 9.8721e-05 - acc: 1.0000 - val_loss: 4.2882 - val_acc: 0.5524\n",
            "Epoch 440/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 9.8410e-05 - acc: 1.0000 - val_loss: 4.2895 - val_acc: 0.5523\n",
            "Epoch 441/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 9.7851e-05 - acc: 1.0000 - val_loss: 4.2897 - val_acc: 0.5519\n",
            "Epoch 442/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 9.7653e-05 - acc: 1.0000 - val_loss: 4.2905 - val_acc: 0.5524\n",
            "Epoch 443/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 9.7322e-05 - acc: 1.0000 - val_loss: 4.2916 - val_acc: 0.5527\n",
            "Epoch 444/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 9.6990e-05 - acc: 1.0000 - val_loss: 4.2924 - val_acc: 0.5522\n",
            "Epoch 445/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 9.6673e-05 - acc: 1.0000 - val_loss: 4.2923 - val_acc: 0.5525\n",
            "Epoch 446/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 9.6314e-05 - acc: 1.0000 - val_loss: 4.2931 - val_acc: 0.5521\n",
            "Epoch 447/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 9.5921e-05 - acc: 1.0000 - val_loss: 4.2936 - val_acc: 0.5526\n",
            "Epoch 448/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 9.5604e-05 - acc: 1.0000 - val_loss: 4.2942 - val_acc: 0.5525\n",
            "Epoch 449/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 9.5366e-05 - acc: 1.0000 - val_loss: 4.2954 - val_acc: 0.5526\n",
            "Epoch 450/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 9.5029e-05 - acc: 1.0000 - val_loss: 4.2962 - val_acc: 0.5523\n",
            "Epoch 451/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 9.4757e-05 - acc: 1.0000 - val_loss: 4.2965 - val_acc: 0.5521\n",
            "Epoch 452/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 9.4478e-05 - acc: 1.0000 - val_loss: 4.2967 - val_acc: 0.5525\n",
            "Epoch 453/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 9.4089e-05 - acc: 1.0000 - val_loss: 4.2975 - val_acc: 0.5524\n",
            "Epoch 454/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 9.3742e-05 - acc: 1.0000 - val_loss: 4.2994 - val_acc: 0.5518\n",
            "Epoch 455/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 9.3504e-05 - acc: 1.0000 - val_loss: 4.2991 - val_acc: 0.5521\n",
            "Epoch 456/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 9.3100e-05 - acc: 1.0000 - val_loss: 4.2989 - val_acc: 0.5529\n",
            "Epoch 457/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 9.2852e-05 - acc: 1.0000 - val_loss: 4.3001 - val_acc: 0.5525\n",
            "Epoch 458/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 9.2562e-05 - acc: 1.0000 - val_loss: 4.3007 - val_acc: 0.5519\n",
            "Epoch 459/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 9.2316e-05 - acc: 1.0000 - val_loss: 4.3014 - val_acc: 0.5516\n",
            "Epoch 460/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 9.1913e-05 - acc: 1.0000 - val_loss: 4.3018 - val_acc: 0.5520\n",
            "Epoch 461/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 9.1634e-05 - acc: 1.0000 - val_loss: 4.3022 - val_acc: 0.5520\n",
            "Epoch 462/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 9.1355e-05 - acc: 1.0000 - val_loss: 4.3044 - val_acc: 0.5515\n",
            "Epoch 463/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 9.1079e-05 - acc: 1.0000 - val_loss: 4.3036 - val_acc: 0.5525\n",
            "Epoch 464/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 9.0647e-05 - acc: 1.0000 - val_loss: 4.3047 - val_acc: 0.5518\n",
            "Epoch 465/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 9.0475e-05 - acc: 1.0000 - val_loss: 4.3051 - val_acc: 0.5522\n",
            "Epoch 466/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 9.0137e-05 - acc: 1.0000 - val_loss: 4.3053 - val_acc: 0.5516\n",
            "Epoch 467/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 8.9788e-05 - acc: 1.0000 - val_loss: 4.3062 - val_acc: 0.5519\n",
            "Epoch 468/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 8.9520e-05 - acc: 1.0000 - val_loss: 4.3072 - val_acc: 0.5519\n",
            "Epoch 469/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 8.9369e-05 - acc: 1.0000 - val_loss: 4.3079 - val_acc: 0.5517\n",
            "Epoch 470/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 8.9063e-05 - acc: 1.0000 - val_loss: 4.3090 - val_acc: 0.5527\n",
            "Epoch 471/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 8.8866e-05 - acc: 1.0000 - val_loss: 4.3083 - val_acc: 0.5515\n",
            "Epoch 472/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 8.8432e-05 - acc: 1.0000 - val_loss: 4.3085 - val_acc: 0.5523\n",
            "Epoch 473/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 8.8174e-05 - acc: 1.0000 - val_loss: 4.3098 - val_acc: 0.5523\n",
            "Epoch 474/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 8.7800e-05 - acc: 1.0000 - val_loss: 4.3107 - val_acc: 0.5519\n",
            "Epoch 475/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 8.7693e-05 - acc: 1.0000 - val_loss: 4.3113 - val_acc: 0.5522\n",
            "Epoch 476/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 8.7342e-05 - acc: 1.0000 - val_loss: 4.3104 - val_acc: 0.5519\n",
            "Epoch 477/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 8.7139e-05 - acc: 1.0000 - val_loss: 4.3120 - val_acc: 0.5522\n",
            "Epoch 478/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 8.6897e-05 - acc: 1.0000 - val_loss: 4.3125 - val_acc: 0.5520\n",
            "Epoch 479/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 8.6570e-05 - acc: 1.0000 - val_loss: 4.3125 - val_acc: 0.5521\n",
            "Epoch 480/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 8.6285e-05 - acc: 1.0000 - val_loss: 4.3140 - val_acc: 0.5522\n",
            "Epoch 481/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 8.5965e-05 - acc: 1.0000 - val_loss: 4.3148 - val_acc: 0.5523\n",
            "Epoch 482/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 8.5951e-05 - acc: 1.0000 - val_loss: 4.3156 - val_acc: 0.5523\n",
            "Epoch 483/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 8.5644e-05 - acc: 1.0000 - val_loss: 4.3160 - val_acc: 0.5519\n",
            "Epoch 484/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 8.5142e-05 - acc: 1.0000 - val_loss: 4.3162 - val_acc: 0.5519\n",
            "Epoch 485/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 8.4958e-05 - acc: 1.0000 - val_loss: 4.3168 - val_acc: 0.5515\n",
            "Epoch 486/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 8.4839e-05 - acc: 1.0000 - val_loss: 4.3178 - val_acc: 0.5522\n",
            "Epoch 487/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 8.4587e-05 - acc: 1.0000 - val_loss: 4.3186 - val_acc: 0.5521\n",
            "Epoch 488/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 8.4258e-05 - acc: 1.0000 - val_loss: 4.3187 - val_acc: 0.5527\n",
            "Epoch 489/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 8.3936e-05 - acc: 1.0000 - val_loss: 4.3193 - val_acc: 0.5526\n",
            "Epoch 490/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 8.3673e-05 - acc: 1.0000 - val_loss: 4.3196 - val_acc: 0.5524\n",
            "Epoch 491/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 8.3548e-05 - acc: 1.0000 - val_loss: 4.3203 - val_acc: 0.5517\n",
            "Epoch 492/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 8.3235e-05 - acc: 1.0000 - val_loss: 4.3209 - val_acc: 0.5520\n",
            "Epoch 493/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 8.2990e-05 - acc: 1.0000 - val_loss: 4.3217 - val_acc: 0.5517\n",
            "Epoch 494/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 8.2746e-05 - acc: 1.0000 - val_loss: 4.3220 - val_acc: 0.5519\n",
            "Epoch 495/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 8.2499e-05 - acc: 1.0000 - val_loss: 4.3224 - val_acc: 0.5525\n",
            "Epoch 496/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 8.2382e-05 - acc: 1.0000 - val_loss: 4.3229 - val_acc: 0.5524\n",
            "Epoch 497/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 8.2077e-05 - acc: 1.0000 - val_loss: 4.3231 - val_acc: 0.5525\n",
            "Epoch 498/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 8.1714e-05 - acc: 1.0000 - val_loss: 4.3243 - val_acc: 0.5516\n",
            "Epoch 499/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 8.1569e-05 - acc: 1.0000 - val_loss: 4.3248 - val_acc: 0.5519\n",
            "Epoch 500/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 8.1396e-05 - acc: 1.0000 - val_loss: 4.3251 - val_acc: 0.5524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdb39b793c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhzLIz8E-Qvg",
        "colab_type": "code",
        "outputId": "2401b394-5ab6-4d8f-c233-f7036108aaa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# 以視覺畫方式檢視訓練過程\n",
        "\n",
        "train_loss = model.history.history[\"loss\"]\n",
        "valid_loss = model.history.history[\"val_loss\"]\n",
        "\n",
        "train_acc = model.history.history[\"acc\"]\n",
        "valid_acc = model.history.history[\"val_acc\"]\n",
        "\n",
        "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
        "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
        "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEICAYAAAB25L6yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWkQkyP1//ILfJvV8P9MAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXhU1fnA8e+bfV9IwhqQfZEdI6Ci\n4kLBpeBGca9WpYtrW9sf1lat2lYtba0Vba21LrWiYlVEXApCcZeA7CCENWHLHhKyJ+f3x7mTTEKW\nIUwymcn7eZ55Zu6559773snknTPnnnuvGGNQSinl/4J8HYBSSinv0ISulFIBQhO6UkoFCE3oSikV\nIDShK6VUgNCErpRSAUITulJKBQhN6MrviMhKESkQkXBfx6JUZ6IJXfkVEekPnAkYYGYHbjeko7al\nVFtpQlf+5nrgC+B54LuuQhGJFJE/iMheESkSkU9EJNKZN0VEPhORQhHJFJEbnPKVInKz2zpuEJFP\n3KaNiNwqIjuAHU7Zn511HBGRNSJyplv9YBH5hYjsFJFiZ35fEVkgIn9w3wkRWSwiP26PN0h1XZrQ\nlb+5HnjZeUwXkR5O+XzgFOB0oBvwc6BWRE4C3gP+AqQA44B1x7G9S4BJwMnO9GpnHd2AfwOvi0iE\nM+8nwFXAhUAc8D2gFHgBuEpEggBEJBk431leKa/RhK78hohMAU4CXjPGrAF2Alc7ifJ7wJ3GmP3G\nmBpjzGfGmArgamCZMeYVY0yVMSbPGHM8Cf13xph8Y0wZgDHmX846qo0xfwDCgWFO3ZuBXxpjvjHW\neqfuV0ARcJ5T70pgpTHm8Am+JUo1oAld+ZPvAh8aY3Kd6X87ZclABDbBN9a3mXJPZbpPiMjdIrLV\n6dYpBOKd7be2rReAa53X1wIvnUBMSjVJD/Qov+D0h38HCBaRQ05xOJAA9ALKgUHA+kaLZgITm1nt\nUSDKbbpnE3XqLkfq9Jf/HNvS3myMqRWRAkDctjUI2NTEev4FbBKRscAI4K1mYlKqzbSFrvzFJUAN\nti97nPMYAXyM7Vd/DvijiPR2Dk6e5gxrfBk4X0S+IyIhIpIkIuOcda4DLhORKBEZDNzUSgyxQDWQ\nA4SIyH3YvnKXZ4GHRGSIWGNEJAnAGJOF7X9/CXjD1YWjlDdpQlf+4rvAP40x+4wxh1wP4EngGmAe\nsBGbNPOBR4EgY8w+7EHKnzrl64Cxzjr/BFQCh7FdIi+3EsMHwPvAdmAv9leBe5fMH4HXgA+BI8A/\ngEi3+S8Ao9HuFtVORG9woVTHEJGzsF0vJxn9x1PtQFvoSnUAEQkF7gSe1WSu2osmdKXamYiMAAqx\nB28f93E4KoBpl4tSSgUIbaErpVSA8Nk49OTkZNO/f39fbV4ppfzSmjVrco0xKU3N81lC79+/P+np\n6b7avFJK+SUR2dvcPO1yUUqpAKEJXSmlAoQmdKWUChCa0JVSKkBoQldKqQDRakIXkedEJFtEmrok\nKM5V5Z4QkQwR2SAiE7wfplJKqdZ40kJ/HpjRwvwLgCHOYy7w9ImHpZRS6ni1Og7dGLPKudN6c2YB\nLzoXHPpCRBJEpJcx5qCXYlQ+lFNcQXlVDTuyiymtrKGqppaSihrKK2uorKklOEgIEqiqMVRU14Ix\nIFJ3x4e6C0voJSaUqnPeiB6M7Zvg9fV648SiPjS8JnSWU3ZMQheRudhWPP369fPCppW3fZqRyxtr\nszhSVs3G/YUcPlLhtXWLtF5Hqa6ge1xEp03oHjPGPAM8A5CWlqZNtk7m9fRM/u+NDcRGhJIUHcbp\ng5I5KSmKbtFhDOsRS3R4iH2EBRMZFkxocBC1xlBTawgLCSIsOAhxsrYxpu61UqpjeCOh78feHNcl\n1SlTnVRtrWFHdgnDesbWlRlj+N1725jQL5EXvjeR6PAT+2hoMleq43lj2OJi4HpntMtkoEj7zzu3\nD7ccZvrjq1ifWVhXti+/lPyjlVw2IfWEk7lSyjda/c8VkVeAqUCyiGQB9wOhAMaYvwJLsfdszABK\ngRvbK1jlHVsPHgHg7XUH6vrxvt5nk/v4ft7v11NKdQxPRrlc1cp8A9zqtYhUu9uVexSApRsP8suL\nRhAUJKzankN8ZChDusf4ODqlVFvpmaJdgDGG2X/9jFkLPqWssoZdOSWEhQRx6Eg56XsLqK6pZfm2\nbM4b0Z2QYP1IKOWv9L83gB0pr2LlN9kUlFaxek8B6zMLycguYV9eKReN7gXA2n0FHC6uoKisirST\nuvk4YqXUidCjXwHsroXr+GhbNlecklpXlpFTTHFFNYNSoukeG05Gdgm5xXaseffYcF+FqpTyAm2h\nB5BPduTyweZDddOuUSyL1mS5lRUBkBAVxuDuMWRkl5DjJPRkTehK+TVN6AHk2n98yfdfWgPArpwS\neyp+I+uzbJJPdBL6zuwSckuchB4T1nHBKqW8TrtcAkRmfmnd67e+3s9dr647ps6Efgls2m+HLCZG\nh9KvWxTFFdV1o16SY7SFrpQ/0xZ6AFj5TTZnPraibtq9i8Xl3OHdmTIkhcoa22pPjAqjZ3wEABuz\niogNDyEiNLhjAlZKtQtN6AFg8foDDaY3ZBUeU+e5G07l/BHd66YTo8LoGWcT+qYDRaRo/7lSfk8T\nuh/5eEcOT6/cyYpt2Q3Kd2aX0D8pignOWZ5HyqubXH5U7/i6xJ0QFVrXQi8ur9buFqUCgCZ0P3Ld\nP77i0fe3cePzq9mXV0pldS33v72J9VlFnD00hTd+eDozRvZsdvmgIGH6yB4kx4QRERpM99iIunnJ\nsXpAVCl/pwdFO7kj5VVUVtce04K+e9F6vtqdXzfdOyESEeHJq8dz6Eg5Ux61feo/nTaUgSn1p/Pf\nc8EIbjlzIABhIUEkx4STW1KhLXSlAoAm9E7ukic/ZVfuUdb88nzCgoPqDmq6kvk1k/oxKCWGK9Ls\nyUMhwUGkJkbVLX/7eUMarM91TXOXPomRmtCVChCa0Duxr3bn1w0pnDp/JZU1tfz20tG89MVeth48\nwpjUeH5z6egml333jinkllS2uo2EyFAAPSiqVADQhN5JZRWU8tj72+gRF05RWRXFzoHOk3vH0SMu\nnK0HId5Jxk0Z2Tveo+241hESpDekUMrf6UHRTmjH4WKmPLqC9L0FXDK+DwmR9oDlj6YOYlzfhLru\nkcSoEz+QeZ4zlHFgSvQJr0sp5VvaQu+EvtpTf7AzNTGqrt/clXyTnFP0W2qhe2rWuD5MHNCNXvGR\nJ7wupZRvaQu9k/lg8yHufXNT3XRqQmTdpW6H9LD3AE2Ktgk92EvdJJrMlQoM2kLvRLKLy/nJq+sI\nCwmi0rmwVu+ESO779sn8YOog4iJsizzMuQlFde2xF99SSnVd2kL3sTe/zuKe/2wA4M/LdlBRXcuH\nd51Vd5CyT2IkocFB9Emob0UHOwm9ptZ0fMBKqU7Loxa6iMwA/gwEA88aYx5pNP8k4DkgBcgHrjXG\nHHuFKHWMdzccZNnWbMb3TWTh6kyumdSP/snRvPHD01m+LZuY8GP/RFOHpgAwO61vR4erlOrExN7j\nuYUKIsHAdmAakAWsBq4yxmxxq/M6sMQY84KInAvcaIy5rqX1pqWlmfT09BON3699vCOH6/7xVd10\nQlQoy39yNkl6ko9SqhkissYYk9bUPE+6XCYCGcaYXcaYSmAhMKtRnZOBj5zXK5qYrxrZmVNSl8xD\ng233yr0XjtBkrpRqM0+6XPoAmW7TWcCkRnXWA5dhu2UuBWJFJMkYk+deSUTmAnMB+vXr19aY/V5R\naRXn/eF/ddM3nzmQEb3i+PaYXj6MSinl77x1UPRu4GwR+Ro4G9gP1DSuZIx5xhiTZoxJS0lJ8dKm\n/c/mg0UNpvsmRjFzbG9E9GxNpVTbedJC3w+4H31LdcrqGGMOYFvoiEgMcLkx5ti7LCgAthywt4H7\n4p7z+HpfAdNO7uHjiJRSgcCTFvpqYIiIDBCRMOBKYLF7BRFJFhHXuu7BjnhRTfho22GeWbWL7rHh\n9IyP4ILRvQgJ1tGjSqkT12oL3RhTLSK3AR9ghy0+Z4zZLCIPAunGmMXAVOB3ImKAVcCt7RizXzpa\nUc0Vf/2crQdt6/z2cwf7OCKlVKDxaBy6MWYpsLRR2X1urxcBi7wbWmBZtvVwXTK/bEIfbj1HE7pS\nyrv01P8O8PnOPO5cuA6A6SN7MP+KsQTp5WqVUl6mCb0DrN1XAMCNZ/Tn/m+P9HE0SqlApUfjOsDu\n3KN0jw3XZK6Ualea0DvA7tyjDEjWG0gopdqXJvR2dKionJtfSGfN3gIGpsT4OhylVIDTPvR2dM9/\nNrDimxwAZo3r7eNolFKBThN6O/hyVx6r9+Tz6c48xqbGc87w7kwa0M3XYSmlApwm9HZw3XNf1d1x\n6K7zh3LO8O4+jkgp1RVoH3o7CHEbYz55YJIPI1FKdSWa0L3s630FlFbWMKFfAl/+4jwiw4J9HZJS\nqovQhO5llz71GQBXTzqJHnERPo5GKdWVaEL3oqyCUgBiw0M4f4T2myulOpYmdC8pLq/iL8szAHj1\n+6eREBXm44iUUl2NjnLxkgff2cKitVlcPakfw3vG+jocpVQXpAndSz7JyOXC0b347aWjfR2KUqqL\n0i4XL9hfWMbBonJOPSnR16EopbowTehesGT9AQDOGJzs40iUUl2ZdrmcgOLyKk5/5COKy6uZOKAb\nQ3po37lSyne0hX4C0vcUUFxeDcC0ET18HI1SqqvzKKGLyAwR+UZEMkRkXhPz+4nIChH5WkQ2iMiF\n3g+181m9J7/udVp/7T9XSvlWqwldRIKBBcAFwMnAVSJycqNqvwReM8aMB64EnvJ2oJ3RpzvzABjf\nL4FRfeJ9HI1SqqvzpA99IpBhjNkFICILgVnAFrc6BohzXscDB7wZZGeUU1zB+sxCfjptKLefN8TX\n4SillEddLn2ATLfpLKfM3QPAtSKSBSwFbm9qRSIyV0TSRSQ9JyenDeF2Hr95dwsiMH1UT1+HopRS\ngPcOil4FPG+MSQUuBF4SkWPWbYx5xhiTZoxJS0lJ8dKmO15ldS1LNhzk+sknMVRHtiilOglPEvp+\noK/bdKpT5u4m4DUAY8znQAQQsIOytx8uprrWMEFPJFJKdSKeJPTVwBARGSAiYdiDnosb1dkHnAcg\nIiOwCd2/+1SacfhIORf/5RMAhveMa6W2Ukp1nFYTujGmGrgN+ADYih3NsllEHhSRmU61nwK3iMh6\n4BXgBmOMaa+gfel/39R/Tw1MifZhJEop1ZBHZ4oaY5ZiD3a6l93n9noLcIZ3Q+uc/rv1MLERIbx9\n6xmEBut5WUqpzkMz0nH4ZEcu/91ymBtP78/AlBhfh6OUUg1oQj8Oy7cdJiI0iFvPHezrUJRS6hia\n0D1UVFrFm1/vZ0K/RMJD9MbPSqnORxO6h36zdAuFpVVccUqqr0NRSqkmaUL3gDGGld/kcMGonlw2\nQRO6Uqpz0oTugR3ZJWQXVzB1mP+e3aqUCnya0FthjGHxOnutsSlDNKErpTovTeit+NcXe3lyRQY9\n4yLokxDp63CUUqpZmtBbUFNr+Ov/dgHw8CWjfByNUkq1TBN6Cz7fmcf+wjIWXD2B80/WW8wppTo3\nTegtWLrpIDHhIZw3oruvQ1FKqVZpQm9BRnYJw3vGEhGqJxIppTo/TejNWLM3n69253NSkl5RUSnl\nHzShN+Pypz8HoH9SlI8jUUopz2hCb0JRWVXd67jIUB9GopRSntOE3oSM7GIAEqJCuXhMLx9Ho5RS\nntGE3oRvDpUA8M5tU0iKCfdxNEop5RlN6E3YfKCI2PAQPTNUKeVXNKE3sjOnhJe/3Mfo1HiCgsTX\n4SillMc8SugiMkNEvhGRDBGZ18T8P4nIOuexXUQKvR9qx7j5hXQAhnTXW8wppfxLqzeJFpFgYAEw\nDcgCVovIYufG0AAYY37sVv92YHw7xNruqmtq2ZN3FIDrTuvv22CUUuo4edJCnwhkGGN2GWMqgYXA\nrBbqXwW84o3gOtq3/rQKY+DPV45jsLbQlVJ+xpOE3gfIdJvOcsqOISInAQOAj5qZP1dE0kUkPScn\n53hjbVcHCsvYlWtb51OH6rVblFL+x9sHRa8EFhljapqaaYx5xhiTZoxJS0npXDeL+HiH/YJ5784z\niY/Sk4mUUv7Hk4S+H+jrNp3qlDXlSvywu6W8qobHl+1gcPcYhvWI9XU4SinVJp4k9NXAEBEZICJh\n2KS9uHElERkOJAKfezfE9vf1vkIOFpXz8+nDdKiiUspvtZrQjTHVwG3AB8BW4DVjzGYReVBEZrpV\nvRJYaIwx7RNq+1m7rwCAiQO6+TgSpZRqu1aHLQIYY5YCSxuV3ddo+gHvhdVxyipreHfDQQamRJMQ\nFebrcJRSqs26/Jmi76w/wJaDR/jJtKG+DkUppU5Il0/oX+3JJzEqlItG61UVlVL+rUsndGMMX+7O\nI61/N0T0YKhSyr916YT+/qZDZOaXMWNkT1+HopRSJ6zLJvS8kgp+vmgDw3vGMmtcb1+Ho5RSJ6zL\nJvSPd+RSXFHNY1eMISS4y74NSqkA0mUz2Wc7c0mICmVU73hfh6KUUl7RJRO6MYZPM/KYPCBJzwxV\nSgWMLpnQM/PL2F9YxumDk3wdilJKeU2XTOjLth4G4PRBmtCVUoGjyyV0YwwvfbGXcX0TGNxdr6yo\nlAocXS6h78wpYXfuUWanpfo6FKWU8qoul9A/zcgD4MzBnesGG0opdaK6VEKvqqnlpS/2Miglmn5J\nUb4ORymlvKpLJfRPMnLJyC7h7m8N83UoSinldV0qoX+xK4/QYGHqML0JtFIq8HSphP5ZRh5jUhOI\nDAv2dShKKeV1XSahZ2QXs3F/EdNH9vB1KEop1S66TEJ/fU0WwUHCJeP7+DoUpZRqFx4ldBGZISLf\niEiGiMxrps53RGSLiGwWkX97N8wTU1VTy5tr93POsBS6x0b4OhyllGoXrd4kWkSCgQXANCALWC0i\ni40xW9zqDAHuAc4wxhSISKc66vj+pkNkF1dw5an9fB2KUkq1G09a6BOBDGPMLmNMJbAQmNWozi3A\nAmNMAYAxJtu7YZ6Yf3yymwHJ0Zw7vFN9zyillFd5ktD7AJlu01lOmbuhwFAR+VREvhCRGU2tSETm\niki6iKTn5OS0LeLjtC6zkHWZhdx4Rn+9VK5SKqB566BoCDAEmApcBfxdRBIaVzLGPGOMSTPGpKWk\ndMyp9/9Zm0V4SBCX6sFQpVSA8ySh7wf6uk2nOmXusoDFxpgqY8xuYDs2wftUTa3h3Q0HOf/kHsRG\nhPo6HKWUaleeJPTVwBARGSAiYcCVwOJGdd7Cts4RkWRsF8wuL8bZJusyC8g7WsmMkT19HYpSSrW7\nVhO6MaYauA34ANgKvGaM2SwiD4rITKfaB0CeiGwBVgA/M8bktVfQnlq2NZuQIOHsYXplRaVU4Gt1\n2CKAMWYpsLRR2X1urw3wE+fRaSzbcpiJA7oRp90tSqkuIGDPFN1xuJgd2SWcP0JP9VdKdQ0Bm9Bf\n+SqTsOAgZo3r7etQlFKqQwRsQl+29TBnDU0mKSbc16EopVSHCMiEvi+vlH35pZw5RA+GKqW6joBM\n6B9tOwzAmUOSfRyJUkp1nIBM6O9tOsSQ7jEMTInxdShKKdVhPBq26E/Kq2pYs7eAm84c4OtQ/FdF\nCYRGwZEsOLwFhs2A2hoIcu70dDQX9q+FAWdBaATUVMHGRRDbA6K7Q/IQ2PI2FO61yweHQlCILU8a\nDBHxdj1FWRAUCrtXQkQCZKVDXG/oNcbWOXKwvn5EPJTlw/b3IaEfHNoEKcMgtidUFNvlAfJ3QmEm\njJkDR3OgNNfGkDQYIhPtevZ9ZvcvPhWikqD4IMT0hCP77bpCwsHU2v2MiINuA22sVWVQcQSqK6Db\nIBCx090GQXkhlORAdJLd1+JDUHkUwmMhPM6+T5VH7XoL9kJtFaSMsNsq2GPfWwkGUwMhETbO6nKo\nrbbvvam1+1eaZ9+jiATA1JfV1kJ0so0xNNK+56V5dp3BoXY9pfkQ1wvKCqGmElKGQ3AYVJXCwQ32\n73M0x24vMtE+jubYZWN7Qf4uCA6x7110io2vqgyiutk4ygrtexmVbOtlb4Oeo+3frbwIJAh6jLSv\nK4ptPCKQOMBuqyzfrqfbIDu/+IB9L6KS7fscEm7f46qjEBJp31uMjS80yu5LwW77t+o20C4XFARh\nMVBy2G4/KBQqS2xZWLT9u8X0sH+T4FDoOQpqqu17UlVq60UmQPkRu97QSBtHUAgYY/8upsa+n9Ep\ndp2FmXDkgF0uoZ+tn5sB1WWQ2B9Ksu3/TvcRXv/XDbiEvu1QMdW1hvF9j7mUjPJESTbMHwLjr4W9\nn9sEeebd8PF8mHqPTagHvrZ1e4y2H+CKYsje7L0YNv+nfdchQfUJsiVhsU5SrbLLIPYfOijEJoLG\nQqNsEoD6pFxRYhOQu+gUmww2v9n08sFhNkF4KiQSMDbWloTHQ0WR3Y+Q8Ib1w2KhstjOCw6Dmor6\nee5fNIhNTM1pHPumRfXLNyA2WdZWt7y+QDXjEU3ontiQZf/RRqe2kNBra23rsVszrfjiw7D7fzB6\ntm1BdCUrfmufv/5XfdnH8+3zyt/Vl3UbCIc32hZP8lCY/CMYOh12/Ne2bFOGwaBz6lulvcfDjg9h\n5woYONW2rmJ6wN5Pbespujv0O822zg9ttC222F629VpeaL80IrvZFk72Ztuqi05xWqHitKbjbYsx\nJMx+McX2smWleXB4k22lVx6F3hNsi6/CaXV1P9m2FqOTbYs0MtF+aQ06zya90lzbgq+ttsk8JMxu\np7YGMJC/27aao5NtAgeb/IKdf6+aKijKtPsbEtHwl05QsE2Cwc5orKqjNrHXVtv3tuSQ3Y+qMrut\nkEhbJyjUvq8SBGFRdhu11Xb9VWW2FeqaNsZ+UST0hbydtnUfEe+0vqvsduP72l8okYn2S7qq3K4j\nKMROH9kPcal2n2pr7bLBofaLodL5wgqNtPtRU2kf4XH2bxcRb+MLCoayAru+oFC7PGJjK8t3Wtmh\n9pdARIL99VVVZpeJiLefk/A4W8/1fyli34PSfPt+BIXYzwXY+MEuH9Pd/r1qKu26q8vt3z8i3n4G\nYnra+LK32H2oKrUt7OpK++UWFOp8mTt/L9d77/plFRxqP3OlefYzGt/Xfm6K9tu/Q+JJNu7sLfaz\nG9s+lyMRe5Jnx0tLSzPp6eleXWdVTS3T/7QKgOU/PRtpLhmv+j189DDctgaSB9uywkzYsNB+WFc6\nSe2WFdBnQsNla6rthygo2H4Qdq+C4RfVdyN46miu/ecJaocbVi/5sf2pm/a9pucbA8vuh9BomPp/\ntqzyKKz7Nyy92yZO18/fc+6Fb96DA2tti+rcX0KvsfbD/Nx0uGohDLvA+/uglGqSiKwxxqQ1NS+g\nWuibDxxhV+5RHp8zrvlkDrD7Y/tcsLs+oX/1DHz2RMN6G149NqE/fZp9vm21TZw7PoQZj8LkH9TX\nqSiB8BYOyJYfgd8PgtPvgG891Hw9YyDzS9s6HTKt+XpVZbZlEJ9qp9Ofs8+uhL7nEzi4Hk671U5/\nPB8+/bPtq3Ql9GUP2PcA4M71NmEXZdmW9tk/t7HU1tS3OgHuyXL6MZVSnUFAJfRtB48AML6fW3dL\nTbXzs8gtwYdG2ufSfJuoDm20P/Ma2/2xnX80F2Kcfs/c7XZe8WEo3Gdf7/sMxnzHHhzK3QFPpsHF\nj9uffBJkE2l1hV0+NKJ+ua9fapjQa2vhnxfA6CvswaN/z7E/CwEeKLIHmYoP2F8DfU6pX+6tH9k+\n494T4Dsv1pdvfsuu59XrbIu732m26+PjP9r5RVl2m0FBsGulLes93h4IBOg+vH5dIg2TOWgyV6qT\nCayEfqiYqLBg+iZG1Rf+theMmAlX/KO+LMTpr3xzrk3QH8+3fWTuTr7EjtRY8zwsuQsu/pPty3R5\nanJ9t8SWt+0BxH6TbD8Z2GVc4vrA69+1B57uWFuf0GuqGm5zfzpkfmEf3UfWJ3OwR8mfmlQ//bOd\nts+2pqr+AOCBtbDxtfo6r3/XPodG2+dNb9jjBlWlth+vYLftC836yn4RTbgezv91k++tUqrzC6iE\nvml/EcN6xtbfaq4w0x4E2bQIxl4F/3vEdofUVtcv5DrgV+uWXGc84gy9ewvWL7RlS37ccGOuZO5y\nNBu2vtN0YK7EWllsR5BMnGun3RP6sgfgkz/VT2dvhnHX2AM8nz4OT5/ecJ2r/2Fb8lXOCIH4vvbA\n2/pXj92+a5TFoQ3wwb32dWqaTejfvAtrXrBdK996+PiPBSilOo2AObGosLSSrzMLmTLY7ezQ3avq\nX798OWSthpytkLej6ZVM+TEMvxjGXmlHPoBtLbuLSmo9mOShLc939VXXVNhxtVuX1CfztO/BrV9B\n30lw6k12ZISrLsD3PrTPK38Lf5kAXzxlp2c/b5N/7jf127nmjYbb3b0K1r1sX6eeap+X/BgOrrO/\nSDSZK+XXAqaFvvKbHGpqDecO715fmLW6+QVSRtgEdmBt/bjZcdfYljnYoU1hMbYfvMdo2zVRcghu\nXQ2vXmOH0xUfbHrdp99uE2Z0ij342ZL5g+tfz1oAoy63ffw3OYk71+3L59tP2L58d64EHdcHpj0I\nb/3QTv/igB0e5hoXPPxi2Lakfrn+Z0KfNNvNAzDw7JbjVEp1egHTQl+29TDJMeGMdY0///BXsOaf\nDStd63ayyeDz4KpX4OblMP462yJ2JXOwBwGTnGQb2xPmrrSt4+gk+N770H+KnXfGnc6JHcCkH9rW\n9YTr7UkD0clw5Ssw9AKI79cwlonfbzgdFGK/UFwHbF0inbPwgkLhlO/a8doufSfVLxvTHcZdDT/d\nDnNetskc4Psfw10bYcpPoO/k+mXj+8BN/7VfWj1G2QOmSim/FhAJvabWsGp7DucMS6nvP3cNQXRP\nVD1G1b+OSrKjUnqNgVlP1reI3aUMs8/hsfaU6X5uByXHXWOfx19nh/kNPAem3FW/jMvwC+HqhTDT\niSemp03m595rk2xif1suwU2fxOQ6rTrMOdjqPhyy11j7HNu7fjx7bA8YcXF9ne7D7enHqafATR/Y\nvnawJ2gEBdlkf/PyrncClVcxNBQAABVlSURBVFIBKCAS+s6cEo6UVzN5oNO/7X6y1Dn31r+OcWvd\nRntwJca0m+xzWNSx8wadY4cSJg+xSfT6t1o++8s1FDA6BS58zHb3nH+/7SaB5k9Fd12jJLSJGFx9\n9dEe9Ou7zF0Jt3xUn8CjutmhlEopv+dRH7qIzAD+DAQDzxpjHmk0/wbg98B+p+hJY8yzXoyzRV/v\nKwDcxp//xxlFMuNRGHCm7RbJ3tawFRrlQULvNwmufQN6jTvxIJOG2OGD5/2qYXmM8yXQXEJ3fUmc\n/X/1ZTMetWeZDp1u+8eHTPc8juhkz77MlFJ+p9WELiLBwAJgGpAFrBaRxcaYLY2qvmqMua0dYmxV\n+p4CEqJCGZAcba+a5hqLneD0W7tawe48TWqDz/dOkBFxcO+BY8tjW0no4TH2l4A797NSXWd/KqW6\nPE9a6BOBDGPMLgARWQjMAhondJ8wxvBpRi7T+gqy/EF7QR2wB/v6Tmx+QU+GH3YE17BEV3+4Ukq1\nkScJvQ+Q6TadBUxqot7lInIWsB34sTEms3EFEZkLzAXo169f49ltsi+/lANF5fyo27/gk6VOxGlw\ny/KWF+ws3Q6hEXDdW/ZiWkopdQK8dVD0HaC/MWYM8F/ghaYqGWOeMcakGWPSUlK8c7/PbYeKGSxZ\nDDi4tL5w0vebX8AlPM4r2/eKQed0ni8YpZTf8iSh7wf6uk2nUn/wEwBjTJ4xxnVF/GeBU+ggO3NK\nWBJ2b8PCPi1sftB59lmH6SmlAownXS6rgSEiMgCbyK8ErnavICK9jDGu0yZnAlu9GmULdmYfJUIa\nXeQqsYXbz1396rEXxVJKqQDQakI3xlSLyG3AB9hhi88ZYzaLyINAujFmMXCHiMwEqoF84IZ2jLkh\n1+3Q3AW18MMj2HWnFKWUCix+fceimlpD8IONbjV3d8ax1ztRSqkA0dIdi/z6TNG9uSUNC4ZfrMlc\nKdVl+XVC37nH7S5DA86Gy//RfGWllApwfp3Q87My6ieSh+g1SZRSXZpfJ/SqPLcWeogmc6VU1+bf\nCb0ou37C/bZySinVBfl3Qj9aWD+hY8uVUl2c3yb0kopqgquK6wtqNaErpbo2v03o+/JKiaW0vsD9\n9mpKKdUF+e1NovfmHSVWSilPHErEDW9BXG9fh6SUUj7lty30vfm2hR4alWBveKwX21JKdXH+m9Dz\nSkkMLic4Mt7XoSilVKfgtwn9YFEZCUFl9TdfVkqpLs5vE/rhIxX2oGhnulGFUkr5kH8eFC3N52cF\nDxJHobbQlVLK4Zct9KqMFZzLV3Yitpdvg1FKqU7CLxN6cVEBAFXBUTDheh9Ho5RSnYNfJvSygkMA\nfHbp5xAW7eNolFKqc/DLhG5KDnHERBEbp0MWlVLKxS8TetDRHHJMPLHh/nlMVyml2oNHCV1EZojI\nNyKSISLzWqh3uYgYEWnyfnfeElKaTQ4JRGtCV0qpOq0mdBEJBhYAFwAnA1eJyMlN1IsF7gS+9HaQ\njYVVFJBr4oiJ0ISulFIunrTQJwIZxphdxphKYCEwq4l6DwGPAuVejK9JQdWllJoIosM0oSullIsn\nCb0PkOk2neWU1RGRCUBfY8y7La1IROaKSLqIpOfk5Bx3sC4hteXUBIcTHKQX5FJKKZcTPigqIkHA\nH4GftlbXGPOMMSbNGJOWkpLS5m2G1FRQG6z3EFVKKXee9FnsB/q6Tac6ZS6xwChgpdhL2PYEFovI\nTGNMurcCrWMMIaaC2lBN6Eodr6qqKrKysigvb/eeUXWCIiIiSE1NJTQ01ONlPEnoq4EhIjIAm8iv\nBK52zTTGFAHJrmkRWQnc3S7JHKCmkiAMhGhCV+p4ZWVlERsbS//+/RG9h0CnZYwhLy+PrKwsBgwY\n4PFyrXa5GGOqgduAD4CtwGvGmM0i8qCIzGxzxG1VVWafQyM7fNNK+bvy8nKSkpI0mXdyIkJSUtJx\n/5LyaJiIMWYpsLRR2X3N1J16XBEcLyehiyZ0pdpEk7l/aMvfyf/OFK3WhK6UUk3xv4ReZX+C1Gof\nulJ+p7CwkKeeeqpNy1544YUUFhZ6OaLA4n8J3WmhG03oSvmdlhJ6dXV1i8suXbqUhISE9gjrhBhj\nqK2t9XUYgD/eschpoROiXS5KnYhfv7OZLQeOeHWdJ/eO4/5vj2x2/rx589i5cyfjxo1j2rRpXHTR\nRfzqV78iMTGRbdu2sX37di655BIyMzMpLy/nzjvvZO7cuQD079+f9PR0SkpKuOCCC5gyZQqfffYZ\nffr04e233yYysmFOeOedd3j44YeprKwkKSmJl19+mR49elBSUsLtt99Oeno6IsL999/P5Zdfzvvv\nv88vfvELampqSE5OZvny5TzwwAPExMRw9913AzBq1CiWLFkCwPTp05k0aRJr1qxh6dKlPPLII6xe\nvZqysjKuuOIKfv3rXwOwevVq7rzzTo4ePUp4eDjLly/noosu4oknnmDcuHEATJkyhQULFjB27NgT\nev/9MKE7o1y0ha6U33nkkUfYtGkT69atA2DlypWsXbuWTZs21Q3Pe+655+jWrRtlZWWceuqpXH75\n5SQlJTVYz44dO3jllVf4+9//zne+8x3eeOMNrr322gZ1pkyZwhdffIGI8Oyzz/LYY4/xhz/8gYce\neoj4+Hg2btwIQEFBATk5Odxyyy2sWrWKAQMGkJ+f3+q+7NixgxdeeIHJkycD8Jvf/IZu3bpRU1PD\neeedx4YNGxg+fDhz5szh1Vdf5dRTT+XIkSNERkZy00038fzzz/P444+zfft2ysvLTziZgx8mdFNV\nigCERfk6FKX8Wkst6Y40ceLEBmOtn3jiCd58800AMjMz2bFjxzEJfcCAAXWt21NOOYU9e/Ycs96s\nrCzmzJnDwYMHqaysrNvGsmXLWLhwYV29xMRE3nnnHc4666y6Ot26dWs17pNOOqkumQO89tprPPPM\nM1RXV3Pw4EG2bNmCiNCrVy9OPfVUAOLi7D2QZ8+ezUMPPcTvf/97nnvuOW644YZWt+cJv+tDr63U\nFrpSgSQ6uv6uYytXrmTZsmV8/vnnrF+/nvHjxzc5Fjs8PLzudXBwcJP977fffju33XYbGzdu5G9/\n+1ubzo4NCQlp0D/uvg73uHfv3s38+fNZvnw5GzZs4KKLLmpxe1FRUUybNo23336b1157jWuuuea4\nY2uK3yX0aiehB4VpH7pS/iY2Npbi4uJm5xcVFZGYmEhUVBTbtm3jiy++aPO2ioqK6NPHXkfwhRde\nqCufNm0aCxYsqJsuKChg8uTJrFq1it27dwPUdbn079+ftWvXArB27dq6+Y0dOXKE6Oho4uPjOXz4\nMO+99x4Aw4YN4+DBg6xevRqA4uLiui+fm2++mTvuuINTTz2VxMTENu+nO79L6K4Wuo5DV8r/JCUl\nccYZZzBq1Ch+9rOfHTN/xowZVFdXM2LECObNm9egS+N4PfDAA8yePZtTTjmF5OS6q5Pwy1/+koKC\nAkaNGsXYsWNZsWIFKSkpPPPMM1x22WWMHTuWOXPmAHD55ZeTn5/PyJEjefLJJxk6dGiT2xo7dizj\nx49n+PDhXH311ZxxxhkAhIWF8eqrr3L77bczduxYpk2bVtdyP+WUU4iLi+PGG29s8z42JsYYr63s\neKSlpZn09OO/3EvJ8vnEfPwQr5z/BVdNGdEOkSkVuLZu3cqIEfp/0xkcOHCAqVOnsm3bNoKCmm5b\nN/X3EpE1xpgm7wrndy30owNn8MPKOwnWg6JKKT/14osvMmnSJH7zm980m8zbwu8SemnsAN6rnURo\naLCvQ1FKqTa5/vrryczMZPbs2V5dr98l9Koae8Q5LFgTulJKufO7hF5ZbRN6aLBeMU4ppdz5X0J3\ntdBD/C50pZRqV36XFV0t9LBgvwtdKaXald9lxbqEri10pbqEmJgYwA7zu+KKK5qsM3XqVNoyDDrQ\n+F1WdB0UDdUWulJdSu/evVm0aJGvw2hSa5f+7Sh+d3EubaEr5SXvzYNDG727zp6j4YJHmp09b948\n+vbty6233gpQd3naH/zgB8yaNYuCggKqqqp4+OGHmTVrVoNl9+zZw8UXX8ymTZsoKyvjxhtvZP36\n9QwfPpyysrImt/fggw/yzjvvUFZWxumnn87f/vY3RISMjAx+8IMfkJOTQ3BwMK+//jqDBg3i0Ucf\n5V//+hdBQUFccMEFPPLII0ydOpX58+eTlpZGbm4uaWlp7Nmzh+eff57//Oc/lJSUUFNTw7vvvtvs\nPrz44ovMnz8fEWHMmDE89dRTjBkzhu3btxMaGsqRI0cYO3Zs3XRbeZTQRWQG8GcgGHjWGPNIo/k/\nAG4FaoASYK4xZkubo2pBpbbQlfJbc+bM4a677qpL6K+99hoffPABERERvPnmm8TFxZGbm8vkyZOZ\nOXNms/fVfPrpp4mKimLr1q1s2LCBCRMmNFnvtttu47777O2Pr7vuOpYsWcK3v/1trrnmGubNm8el\nl15KeXk5tbW1vPfee7z99tt8+eWXREVFeXQJ3bVr17Jhwwa6detGdXV1k/uwZcsWHn74YT777DOS\nk5PJz88nNjaWqVOn8u6773LJJZewcOFCLrvsshNK5uBBQheRYGABMA3IAlaLyOJGCfvfxpi/OvVn\nAn8EZpxQZM1wtdDDtYWu1IlpoSXdXsaPH092djYHDhwgJyeHxMRE+vbtS1VVFb/4xS9YtWoVQUFB\n7N+/n8OHD9OzZ88m17Nq1SruuOMOAMaMGcOYMWOarLdixQoee+wxSktL667JMnXqVPbv38+ll14K\nQESEvXLrsmXLuPHGG4mKsmehe3IJ3WnTptXVM8Y0uQ8fffQRs2fPrruejKv+zTffzGOPPcYll1zC\nP//5T/7+9797+jY2y5MW+kQgwxizC0BEFgKzgLqEboxxv+1JNNBuF4ipqrGr1ha6Uv5p9uzZLFq0\niEOHDtVdBOvll18mJyeHNWvWEBoaSv/+/dt0uVt35eXl/OhHPyI9PZ2+ffvywAMPnPAldBsv734J\n3ePdhzPOOIM9e/awcuVKampqGDVq1HHH1pgnWbEPkOk2neWUNSAit4rITuAx4I6mViQic0UkXUTS\nc3Jy2hIvldU1gPahK+Wv5syZw8KFC1m0aFHdqe9FRUV0796d0NBQVqxYwd69e1tcx1lnncW///1v\nADZt2sSGDRuOqeNKpsnJyZSUlNQdUI2NjSU1NZW33noLgIqKCkpLS5k2bRr//Oc/KS0tBRpeQnfN\nmjUALR6UbW4fzj33XF5//XXy8vIarBfsJQCuvvpqr11x0WtZ0RizwBgzCPg/4JfN1HnGGJNmjElL\nSUlp03bqW+h6pqhS/mjkyJEUFxfTp08fevXqBcA111xDeno6o0eP5sUXX2T48OEtruOHP/whJSUl\njBgxgvvuu49TTjnlmDoJCQnccsstjBo1iunTp9fdNQjgpZde4oknnmDMmDGcfvrpHDp0iBkzZjBz\n5kzS0tIYN24c8+fPB+Duu+/m6aefZvz48eTm5jYbU3P7MHLkSO69917OPvtsxo4dy09+8pMGyxQU\nFHDVVVd5/ga2oNXL54rIacADxpjpzvQ9AMaY3zVTPwgoMMbEt7Tetl4+98PNh3hr3X4enzNeW+lK\nHSe9fG7nsmjRIt5++21eeumlJucf7+VzPelDXw0MEZEBwH7gSuDqRhsYYozZ4UxeBOygnXxrZE++\nNbLpAyVKKeUvbr/9dt577z2WLl3qtXW2mtCNMdUichvwAXbY4nPGmM0i8iCQboxZDNwmIucDVUAB\n8F2vRaiUUgHoL3/5i9fX6dE4dGPMUmBpo7L73F7f6eW4lFLtxBjT7Phu1Xm05W5y2gmtVBcSERFB\nXl5em5KF6jjGGPLy8urGyHvK7079V0q1XWpqKllZWbR12LDqOBEREaSmph7XMprQlepCQkNDGTBg\ngK/DUO1Eu1yUUipAaEJXSqkAoQldKaUCRKtnirbbhkVygJYv2NC8ZKD5c3ADk+5z16D73DWcyD6f\nZIxp8topPkvoJ0JE0ps79TVQ6T53DbrPXUN77bN2uSilVIDQhK6UUgHCXxP6M74OwAd0n7sG3eeu\noV322S/70JVSSh3LX1voSimlGtGErpRSAcLvErqIzBCRb0QkQ0Tm+ToebxGR50QkW0Q2uZV1E5H/\nisgO5znRKRcRecJ5DzaIyATfRd52ItJXRFaIyBYR2SwidzrlAbvfIhIhIl+JyHpnn3/tlA8QkS+d\nfXtVRMKc8nBnOsOZ39+X8beViASLyNcissSZDuj9BRCRPSKyUUTWiUi6U9aun22/SugiEgwsAC4A\nTgauEpGTfRuV1zwPzGhUNg9YbowZAix3psHu/xDnMRd4uoNi9LZq4KfGmJOBycCtzt8zkPe7AjjX\nGDMWGAfMEJHJwKPAn4wxg7E3ibnJqX8T9paOg4E/OfX80Z3AVrfpQN9fl3OMMePcxpy372fbGOM3\nD+A04AO36XuAe3wdlxf3rz+wyW36G6CX87oX8I3z+m/AVU3V8+cH8DYwravsNxAFrAUmYc8aDHHK\n6z7n2DuFnea8DnHqia9jP879THWS17nAEkACeX/d9nsPkNyorF0/237VQgf6AJlu01lOWaDqYYw5\n6Lw+BPRwXgfc++D8tB4PfEmA77fT/bAOyAb+C+wECo0x1U4V9/2q22dnfhGQ1LERn7DHgZ8Dtc50\nEoG9vy4G+FBE1ojIXKesXT/bej10P2GMMSISkGNMRSQGeAO4yxhzxP32aIG438aYGmCciCQAbwLD\nfRxSuxGRi4FsY8waEZnq63g62BRjzH4R6Q78V0S2uc9sj8+2v7XQ9wN93aZTnbJAdVhEegE4z9lO\necC8DyISik3mLxtj/uMUB/x+AxhjCoEV2C6HBBFxNbDc96tun5358UBeB4d6Is4AZorIHmAhttvl\nzwTu/tYxxux3nrOxX9wTaefPtr8l9NXAEOcIeRhwJbDYxzG1p8XAd53X38X2MbvKr3eOjE8Gitx+\nxvkNsU3xfwBbjTF/dJsVsPstIilOyxwRicQeM9iKTexXONUa77PrvbgC+Mg4naz+wBhzjzEm1RjT\nH/v/+pEx5hoCdH9dRCRaRGJdr4FvAZto78+2rw8ctOFAw4XAdmy/472+jseL+/UKcBCowvaf3YTt\nO1wO7ACWAd2cuoId7bMT2Aik+Tr+Nu7zFGw/4wZgnfO4MJD3GxgDfO3s8ybgPqd8IPAVkAG8DoQ7\n5RHOdIYzf6Cv9+EE9n0qsKQr7K+zf+udx2ZXrmrvz7ae+q+UUgHC37pclFJKNUMTulJKBQhN6Eop\nFSA0oSulVIDQhK6UUgFCE7pSSgUITehKKRUg/h/PFNeXszXTDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIn7MsEAivfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
