{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Day_084_overfitting_skill_compare_HW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chunyuan0221/3rd-ML100days/blob/master/Day_084_overfitting_skill_compare_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhM5v9hG658W",
        "colab_type": "text"
      },
      "source": [
        "## Work\n",
        "### 請結合前面的知識與程式碼，比較不同的 regularization 的組合對訓練的結果與影響：如 dropout, regularizers, batch-normalization 等"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NZaQOxK658a",
        "colab_type": "code",
        "outputId": "4718255a-6c19-472c-9dce-118930ef7114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import os\n",
        "import keras\n",
        "import itertools\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "# Disable GPU\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uiXaxuF658d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6MTgDz0658g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 資料前處理\n",
        "def preproc_x(x, flatten=True):\n",
        "    x = x / 255.\n",
        "    if flatten:\n",
        "        x = x.reshape((len(x), -1))\n",
        "    return x\n",
        "\n",
        "def preproc_y(y, num_classes=10):\n",
        "    if y.shape[-1] == 1:\n",
        "        y = keras.utils.to_categorical(y, num_classes)\n",
        "    return y    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wwyeiai658j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "\n",
        "# Preproc the inputs\n",
        "x_train = preproc_x(x_train)\n",
        "x_test = preproc_x(x_test)\n",
        "\n",
        "# Preprc the outputs\n",
        "y_train = preproc_y(y_train)\n",
        "y_test = preproc_y(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdvzU5A4658l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.regularizers import l1, l2\n",
        "def build_mlp(input_shape, output_neuron=10, regular_mode=0, reg_value=1e-1, drop_value=0, layer_neuron=[512, 256, 128]):\n",
        "    \"\"\"Code Here\n",
        "    建立你的神經網路\n",
        "    \"\"\"\n",
        "    regular_class = [None, l1, l2]\n",
        "    input_layer = keras.layers.Input(shape=input_shape)\n",
        "    for i, neuron in enumerate(layer_neuron):\n",
        "        if i == 0:\n",
        "            if regular_mode==0 and drop_value==0:\n",
        "                x = keras.layers.BatchNormalization()(input_layer)\n",
        "                x = keras.layers.Dense(units=neuron, \n",
        "                                       activation='relu',\n",
        "                                       name='hidden_layer%s'%i)(x)\n",
        "            elif regular_mode>1 and drop_value==0:     # 做batch normalization + regularization\n",
        "                x = keras.layers.BatchNormalization()(input_layer)\n",
        "                x = keras.layers.Dense(units=neuron, \n",
        "                                       activation='relu',\n",
        "                                       name='hidden_layer%s'%i,\n",
        "                                       kernel_regularizer=regular_class[regular_mode](reg_value))(x)\n",
        "            elif regular_mode==0 and drop_value > 0:    # 做batch normalization + dropout\n",
        "                x = keras.layers.BatchNormalization()(input_layer)\n",
        "                x = keras.layers.Dense(units=neuron, \n",
        "                                       activation='relu',\n",
        "                                       name='hidden_layer%s'%i)(x)\n",
        "                x = keras.layers.Dropout(drop_value)(x)\n",
        "            else:                                      # 都做, batch normalization + regularization + dropout\n",
        "                x = keras.layers.BatchNormalization()(input_layer)\n",
        "                x = keras.layers.Dense(units=neuron, \n",
        "                                       activation='relu',\n",
        "                                       name='hidden_layer%s'%i,\n",
        "                                       kernel_regularizer=regular_class[regular_mode](reg_value))(x)\n",
        "                x = keras.layers.Dropout(drop_value)(x)\n",
        "        else:                                          \n",
        "            if regular_mode==0 and drop_value==0:        # 只做batch normalization\n",
        "                x = keras.layers.BatchNormalization()(x)\n",
        "                x = keras.layers.Dense(units=neuron, \n",
        "                                       activation='relu',\n",
        "                                       name='hidden_layer%s'%i)(x)\n",
        "            elif regular_mode>1 and drop_value==0:     # 做batch normalization + regularization\n",
        "                x = keras.layers.BatchNormalization()(x)\n",
        "                x = keras.layers.Dense(units=neuron, \n",
        "                                       activation='relu',\n",
        "                                       name='hidden_layer%s'%i,\n",
        "                                       kernel_regularizer=regular_class[regular_mode](reg_value))(x)\n",
        "            elif regular_mode==0 and drop_value > 0:    # 做batch normalization + dropout\n",
        "                x = keras.layers.BatchNormalization()(x)\n",
        "                x = keras.layers.Dense(units=neuron, \n",
        "                                       activation='relu',\n",
        "                                       name='hidden_layer%s'%i)(x)\n",
        "                x = keras.layers.Dropout(drop_value)(x)\n",
        "            else:                                      # 都做, batch normalization + regularization + dropout\n",
        "                x = keras.layers.BatchNormalization()(x)\n",
        "                x = keras.layers.Dense(units=neuron, \n",
        "                                       activation='relu',\n",
        "                                       name='hidden_layer%s'%i,\n",
        "                                       kernel_regularizer=regular_class[regular_mode](reg_value))(x)\n",
        "                x = keras.layers.Dropout(drop_value)(x)\n",
        "    \n",
        "    out_layer = keras.layers.Dense(units=output_neuron, activation='softmax')(x)\n",
        "    model = keras.models.Model(inputs=[input_layer], outputs=[out_layer])                                   \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGlNd483pHai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Code Here\n",
        "設定超參數\n",
        "\"\"\"\n",
        "EPOCH = 50\n",
        "BATCH_SIZE = 256\n",
        "LEARNING_RATE = 1e-2\n",
        "regular_value = [1e-2, 1e-3, 1e-4   1e-1,]\n",
        "dropout_value = [0, 0.15, 0.25, 0.35]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZjpXTbRosnk",
        "colab_type": "code",
        "outputId": "704e3544-f560-4426-904c-1e871f33b16f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\"Code Here\n",
        "撰寫你的訓練流程並將結果用 dictionary 紀錄\n",
        "\"\"\"\n",
        "results = {}\n",
        "\n",
        "# only BN                      / Reg=0, drop=0\n",
        "\n",
        "# BN + Regular                 / Reg=1 or 2, drop=0\n",
        "\n",
        "# BN + Dropout                 / Reg=0, drop>0\n",
        "\n",
        "# BN + Regular + Dropout       / Reg=1 or 2, drop>0\n",
        "\n",
        "\n",
        "# Regularization模式\n",
        "reg_tag = {0:'off', 1:'L1', 2:'L2'}\n",
        "\n",
        "# dropout不設定，因為設定為只要大於0就可以做dropout\n",
        "# 0代表不做、1代表L1、2代表L2\n",
        "regular_class = [0, 1, 2]\n",
        "\n",
        "for i, drop in enumerate(dropout_value):\n",
        "    for j in regular_class:\n",
        "        keras.backend.clear_session()\n",
        "        print(\"Experiment with BN + regular=%s + dropout=%s\" %(reg_tag[j], drop))\n",
        "        model = build_mlp(x_train.shape[1:], regular_mode=j, drop_value=drop)\n",
        "        model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        model.fit(x_train, y_train,\n",
        "                  epochs=EPOCH,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  validation_data=(x_test, y_test),\n",
        "                  shuffle=True)\n",
        "\n",
        "        results['BN_reg=%s_drop=%s' %(reg_tag[j], drop)]=dict(train_loss=model.history.history['loss'],\n",
        "                                                              valid_loss=model.history.history['val_loss'],\n",
        "                                                              train_acc=model.history.history['acc'],\n",
        "                                                              valid_acc=model.history.history['val_acc'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experiment with BN + regular=off + dropout=0\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 2s 50us/step - loss: 1.9272 - acc: 0.3225 - val_loss: 1.7138 - val_acc: 0.4005\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 1.6177 - acc: 0.4319 - val_loss: 1.6059 - val_acc: 0.4395\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 1.5006 - acc: 0.4747 - val_loss: 1.5459 - val_acc: 0.4614\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 1.4226 - acc: 0.5029 - val_loss: 1.5060 - val_acc: 0.4684\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 1.3578 - acc: 0.5281 - val_loss: 1.4781 - val_acc: 0.4790\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 1.3027 - acc: 0.5477 - val_loss: 1.4607 - val_acc: 0.4854\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 1.2531 - acc: 0.5655 - val_loss: 1.4450 - val_acc: 0.4921\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 1.2070 - acc: 0.5835 - val_loss: 1.4279 - val_acc: 0.5005\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 1.1657 - acc: 0.5985 - val_loss: 1.4161 - val_acc: 0.5033\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 1.1259 - acc: 0.6160 - val_loss: 1.4092 - val_acc: 0.5068\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 1.0847 - acc: 0.6296 - val_loss: 1.4078 - val_acc: 0.5081\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.0486 - acc: 0.6438 - val_loss: 1.4028 - val_acc: 0.5084\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 1.0129 - acc: 0.6559 - val_loss: 1.4031 - val_acc: 0.5146\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.9762 - acc: 0.6719 - val_loss: 1.4211 - val_acc: 0.5108\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.9406 - acc: 0.6842 - val_loss: 1.4017 - val_acc: 0.5137\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 0.9088 - acc: 0.6963 - val_loss: 1.4071 - val_acc: 0.5133\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 0.8744 - acc: 0.7096 - val_loss: 1.4171 - val_acc: 0.5116\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.8407 - acc: 0.7230 - val_loss: 1.4128 - val_acc: 0.5170\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.8076 - acc: 0.7367 - val_loss: 1.4493 - val_acc: 0.5120\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.7823 - acc: 0.7443 - val_loss: 1.4412 - val_acc: 0.5154\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.7473 - acc: 0.7573 - val_loss: 1.4604 - val_acc: 0.5131\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.7159 - acc: 0.7686 - val_loss: 1.4601 - val_acc: 0.5160\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.6852 - acc: 0.7816 - val_loss: 1.4727 - val_acc: 0.5146\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.6600 - acc: 0.7907 - val_loss: 1.4926 - val_acc: 0.5087\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.6275 - acc: 0.8028 - val_loss: 1.5988 - val_acc: 0.4910\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.6023 - acc: 0.8119 - val_loss: 1.5053 - val_acc: 0.5128\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.5745 - acc: 0.8227 - val_loss: 1.6036 - val_acc: 0.4984\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 0.5448 - acc: 0.8356 - val_loss: 1.5851 - val_acc: 0.5003\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.5179 - acc: 0.8455 - val_loss: 1.6229 - val_acc: 0.4981\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.4943 - acc: 0.8534 - val_loss: 1.5980 - val_acc: 0.5086\n",
            "Experiment with BN + regular=L2 + dropout=0\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 3s 55us/step - loss: 98.4161 - acc: 0.3424 - val_loss: 65.1101 - val_acc: 0.4040\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 45.6882 - acc: 0.4485 - val_loss: 30.6646 - val_acc: 0.4386\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 21.6970 - acc: 0.4864 - val_loss: 14.9320 - val_acc: 0.4504\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 10.7513 - acc: 0.5019 - val_loss: 7.7888 - val_acc: 0.4436\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 5.7645 - acc: 0.5122 - val_loss: 4.4415 - val_acc: 0.4827\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 3.5000 - acc: 0.5146 - val_loss: 3.0919 - val_acc: 0.4389\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 2.4625 - acc: 0.5196 - val_loss: 2.5096 - val_acc: 0.4075\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.9968 - acc: 0.5219 - val_loss: 2.1120 - val_acc: 0.4364\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.7720 - acc: 0.5304 - val_loss: 2.1730 - val_acc: 0.3899\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.6699 - acc: 0.5313 - val_loss: 1.7714 - val_acc: 0.4824\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.6198 - acc: 0.5354 - val_loss: 1.8541 - val_acc: 0.4450\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.5925 - acc: 0.5411 - val_loss: 1.7307 - val_acc: 0.4723\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.5751 - acc: 0.5439 - val_loss: 1.6935 - val_acc: 0.4851\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.5659 - acc: 0.5472 - val_loss: 1.8192 - val_acc: 0.4656\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.5598 - acc: 0.5468 - val_loss: 1.7157 - val_acc: 0.4807\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.5519 - acc: 0.5507 - val_loss: 1.8191 - val_acc: 0.4641\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.5460 - acc: 0.5530 - val_loss: 1.7631 - val_acc: 0.4638\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.5465 - acc: 0.5513 - val_loss: 1.8733 - val_acc: 0.4445\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.5405 - acc: 0.5555 - val_loss: 1.8445 - val_acc: 0.4470\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.5359 - acc: 0.5571 - val_loss: 1.8331 - val_acc: 0.4457\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.5371 - acc: 0.5585 - val_loss: 1.7908 - val_acc: 0.4608\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.5313 - acc: 0.5611 - val_loss: 1.8854 - val_acc: 0.4402\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.5281 - acc: 0.5631 - val_loss: 1.7501 - val_acc: 0.4694\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.5287 - acc: 0.5610 - val_loss: 2.1249 - val_acc: 0.4179\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.5245 - acc: 0.5646 - val_loss: 2.1344 - val_acc: 0.3986\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.5191 - acc: 0.5672 - val_loss: 1.8594 - val_acc: 0.4543\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.5186 - acc: 0.5647 - val_loss: 1.7235 - val_acc: 0.4844\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.5137 - acc: 0.5670 - val_loss: 1.9782 - val_acc: 0.4124\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.5125 - acc: 0.5674 - val_loss: 1.8709 - val_acc: 0.4480\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.5082 - acc: 0.5722 - val_loss: 1.9339 - val_acc: 0.4336\n",
            "Experiment with BN + regular=off + dropout=0.15\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 3s 55us/step - loss: 2.1292 - acc: 0.2676 - val_loss: 1.7458 - val_acc: 0.3836\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.8498 - acc: 0.3502 - val_loss: 1.6431 - val_acc: 0.4204\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.7443 - acc: 0.3825 - val_loss: 1.5794 - val_acc: 0.4397\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.6797 - acc: 0.4057 - val_loss: 1.5413 - val_acc: 0.4553\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.6274 - acc: 0.4210 - val_loss: 1.5057 - val_acc: 0.4678\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.5850 - acc: 0.4372 - val_loss: 1.4825 - val_acc: 0.4722\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.5517 - acc: 0.4463 - val_loss: 1.4647 - val_acc: 0.4762\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.5196 - acc: 0.4570 - val_loss: 1.4458 - val_acc: 0.4842\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.4988 - acc: 0.4645 - val_loss: 1.4292 - val_acc: 0.4899\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.4715 - acc: 0.4769 - val_loss: 1.4126 - val_acc: 0.4946\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.4540 - acc: 0.4821 - val_loss: 1.4005 - val_acc: 0.4962\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.4330 - acc: 0.4908 - val_loss: 1.3904 - val_acc: 0.5022\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.4149 - acc: 0.4973 - val_loss: 1.3758 - val_acc: 0.5080\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.3996 - acc: 0.5038 - val_loss: 1.3700 - val_acc: 0.5079\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.3857 - acc: 0.5067 - val_loss: 1.3606 - val_acc: 0.5136\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.3644 - acc: 0.5136 - val_loss: 1.3544 - val_acc: 0.5119\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.3499 - acc: 0.5154 - val_loss: 1.3469 - val_acc: 0.5135\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.3400 - acc: 0.5184 - val_loss: 1.3432 - val_acc: 0.5140\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.3261 - acc: 0.5256 - val_loss: 1.3346 - val_acc: 0.5195\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.3168 - acc: 0.5313 - val_loss: 1.3267 - val_acc: 0.5270\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.3041 - acc: 0.5336 - val_loss: 1.3218 - val_acc: 0.5248\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.2901 - acc: 0.5376 - val_loss: 1.3197 - val_acc: 0.5218\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.2791 - acc: 0.5420 - val_loss: 1.3094 - val_acc: 0.5254\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.2647 - acc: 0.5479 - val_loss: 1.3095 - val_acc: 0.5260\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.2526 - acc: 0.5519 - val_loss: 1.3060 - val_acc: 0.5306\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.2436 - acc: 0.5559 - val_loss: 1.3072 - val_acc: 0.5296\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.2301 - acc: 0.5602 - val_loss: 1.2985 - val_acc: 0.5323\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.2227 - acc: 0.5636 - val_loss: 1.2958 - val_acc: 0.5318\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.2092 - acc: 0.5657 - val_loss: 1.2940 - val_acc: 0.5340\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.2048 - acc: 0.5695 - val_loss: 1.2920 - val_acc: 0.5379\n",
            "Experiment with BN + regular=L2 + dropout=0.15\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 3s 59us/step - loss: 98.6451 - acc: 0.2830 - val_loss: 65.1791 - val_acc: 0.3769\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 45.8327 - acc: 0.3833 - val_loss: 30.7011 - val_acc: 0.4109\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 21.8090 - acc: 0.4262 - val_loss: 14.9710 - val_acc: 0.4348\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 10.8407 - acc: 0.4537 - val_loss: 7.7584 - val_acc: 0.4531\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 5.8386 - acc: 0.4694 - val_loss: 4.4947 - val_acc: 0.4415\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 3.5576 - acc: 0.4818 - val_loss: 2.9515 - val_acc: 0.4715\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 2.5208 - acc: 0.4879 - val_loss: 2.3718 - val_acc: 0.4395\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 2.0519 - acc: 0.4906 - val_loss: 1.9908 - val_acc: 0.4712\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.8338 - acc: 0.4983 - val_loss: 1.8954 - val_acc: 0.4461\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.7276 - acc: 0.5036 - val_loss: 1.7399 - val_acc: 0.4791\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.6832 - acc: 0.5069 - val_loss: 1.7776 - val_acc: 0.4556\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.6560 - acc: 0.5095 - val_loss: 1.7920 - val_acc: 0.4501\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.6459 - acc: 0.5122 - val_loss: 1.7228 - val_acc: 0.4786\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.6360 - acc: 0.5127 - val_loss: 1.7812 - val_acc: 0.4567\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.6290 - acc: 0.5152 - val_loss: 1.6958 - val_acc: 0.4928\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.6223 - acc: 0.5154 - val_loss: 1.8275 - val_acc: 0.4286\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.6198 - acc: 0.5211 - val_loss: 1.7727 - val_acc: 0.4622\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.6198 - acc: 0.5201 - val_loss: 1.7800 - val_acc: 0.4449\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.6159 - acc: 0.5208 - val_loss: 1.7547 - val_acc: 0.4614\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.6105 - acc: 0.5228 - val_loss: 1.7339 - val_acc: 0.4761\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.6036 - acc: 0.5252 - val_loss: 1.7599 - val_acc: 0.4632\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.6048 - acc: 0.5263 - val_loss: 1.6881 - val_acc: 0.4865\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.6026 - acc: 0.5286 - val_loss: 1.9280 - val_acc: 0.4169\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.6014 - acc: 0.5268 - val_loss: 1.7325 - val_acc: 0.4719\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.5987 - acc: 0.5263 - val_loss: 1.6725 - val_acc: 0.4944\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.5927 - acc: 0.5313 - val_loss: 1.8572 - val_acc: 0.4312\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.5956 - acc: 0.5288 - val_loss: 1.8023 - val_acc: 0.4604\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.5948 - acc: 0.5297 - val_loss: 1.7856 - val_acc: 0.4512\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.5879 - acc: 0.5302 - val_loss: 1.6915 - val_acc: 0.4898\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.5893 - acc: 0.5335 - val_loss: 1.8078 - val_acc: 0.4600\n",
            "Experiment with BN + regular=off + dropout=0.25\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 3s 55us/step - loss: 2.2773 - acc: 0.2304 - val_loss: 1.8047 - val_acc: 0.3568\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.9822 - acc: 0.3058 - val_loss: 1.6960 - val_acc: 0.3952\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.8786 - acc: 0.3398 - val_loss: 1.6370 - val_acc: 0.4198\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.8124 - acc: 0.3585 - val_loss: 1.5960 - val_acc: 0.4319\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.7557 - acc: 0.3743 - val_loss: 1.5589 - val_acc: 0.4464\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.7201 - acc: 0.3871 - val_loss: 1.5388 - val_acc: 0.4511\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.6873 - acc: 0.3970 - val_loss: 1.5179 - val_acc: 0.4567\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.6562 - acc: 0.4085 - val_loss: 1.5008 - val_acc: 0.4624\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.6295 - acc: 0.4144 - val_loss: 1.4818 - val_acc: 0.4712\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.6029 - acc: 0.4245 - val_loss: 1.4716 - val_acc: 0.4762\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.5880 - acc: 0.4297 - val_loss: 1.4570 - val_acc: 0.4834\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.5715 - acc: 0.4371 - val_loss: 1.4476 - val_acc: 0.4832\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.5532 - acc: 0.4426 - val_loss: 1.4365 - val_acc: 0.4869\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.5374 - acc: 0.4505 - val_loss: 1.4265 - val_acc: 0.4912\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.5263 - acc: 0.4549 - val_loss: 1.4170 - val_acc: 0.4934\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.5073 - acc: 0.4569 - val_loss: 1.4107 - val_acc: 0.4992\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.4971 - acc: 0.4640 - val_loss: 1.4021 - val_acc: 0.4994\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.4807 - acc: 0.4667 - val_loss: 1.3935 - val_acc: 0.5039\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.4759 - acc: 0.4680 - val_loss: 1.3852 - val_acc: 0.5025\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.4711 - acc: 0.4717 - val_loss: 1.3790 - val_acc: 0.5085\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.4578 - acc: 0.4777 - val_loss: 1.3743 - val_acc: 0.5088\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.4480 - acc: 0.4796 - val_loss: 1.3717 - val_acc: 0.5109\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.4377 - acc: 0.4819 - val_loss: 1.3624 - val_acc: 0.5116\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.4256 - acc: 0.4868 - val_loss: 1.3586 - val_acc: 0.5133\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.4191 - acc: 0.4911 - val_loss: 1.3500 - val_acc: 0.5187\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.4109 - acc: 0.4920 - val_loss: 1.3457 - val_acc: 0.5161\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.3976 - acc: 0.4968 - val_loss: 1.3424 - val_acc: 0.5186\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.3958 - acc: 0.5000 - val_loss: 1.3427 - val_acc: 0.5200\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.3887 - acc: 0.5016 - val_loss: 1.3344 - val_acc: 0.5216\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.3798 - acc: 0.5037 - val_loss: 1.3301 - val_acc: 0.5240\n",
            "Experiment with BN + regular=L2 + dropout=0.25\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 3s 55us/step - loss: 98.5997 - acc: 0.2421 - val_loss: 65.0728 - val_acc: 0.3699\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 45.8234 - acc: 0.3428 - val_loss: 30.6651 - val_acc: 0.3926\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 21.8357 - acc: 0.3917 - val_loss: 14.9676 - val_acc: 0.4236\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 10.8882 - acc: 0.4228 - val_loss: 7.7893 - val_acc: 0.4408\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 5.8815 - acc: 0.4501 - val_loss: 4.4850 - val_acc: 0.4538\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 3.5933 - acc: 0.4640 - val_loss: 2.9574 - val_acc: 0.4723\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 2.5595 - acc: 0.4698 - val_loss: 2.2932 - val_acc: 0.4580\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 2.0847 - acc: 0.4765 - val_loss: 1.9492 - val_acc: 0.4817\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.8754 - acc: 0.4819 - val_loss: 1.9574 - val_acc: 0.4199\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.7737 - acc: 0.4866 - val_loss: 1.8746 - val_acc: 0.4366\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 1.7245 - acc: 0.4886 - val_loss: 1.7400 - val_acc: 0.4697\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 1.7042 - acc: 0.4903 - val_loss: 1.8547 - val_acc: 0.4270\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.6896 - acc: 0.4919 - val_loss: 1.7647 - val_acc: 0.4550\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.6774 - acc: 0.4944 - val_loss: 1.9623 - val_acc: 0.4063\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.6766 - acc: 0.4979 - val_loss: 1.7366 - val_acc: 0.4626\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.6672 - acc: 0.4987 - val_loss: 1.7183 - val_acc: 0.4722\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.6680 - acc: 0.4991 - val_loss: 1.8255 - val_acc: 0.4404\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.6633 - acc: 0.5010 - val_loss: 1.7595 - val_acc: 0.4590\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.6594 - acc: 0.5031 - val_loss: 1.6675 - val_acc: 0.4916\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.6575 - acc: 0.5043 - val_loss: 1.8698 - val_acc: 0.4329\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.6551 - acc: 0.5053 - val_loss: 1.7603 - val_acc: 0.4665\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 1.6509 - acc: 0.5032 - val_loss: 1.7235 - val_acc: 0.4731\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.6503 - acc: 0.5074 - val_loss: 1.8636 - val_acc: 0.4465\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.6570 - acc: 0.5016 - val_loss: 1.7210 - val_acc: 0.4765\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.6473 - acc: 0.5051 - val_loss: 1.7096 - val_acc: 0.4687\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 1.6476 - acc: 0.5074 - val_loss: 1.7832 - val_acc: 0.4510\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.6455 - acc: 0.5054 - val_loss: 1.6893 - val_acc: 0.4846\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.6401 - acc: 0.5094 - val_loss: 1.8672 - val_acc: 0.4257\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.6484 - acc: 0.5070 - val_loss: 1.7087 - val_acc: 0.4772\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.6427 - acc: 0.5080 - val_loss: 1.7273 - val_acc: 0.4767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNfY5CPo8zad",
        "colab_type": "code",
        "outputId": "b2d01842-c904-4c3c-e45a-04d5504af7bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "colorbar = ['r', 'g', 'b', 'y', 'm']\n",
        "for i, drop in enumerate(dropout_value):\n",
        "    for j in regular_class:\n",
        "        #plt.figure(figsize=(8, 6))\n",
        "        plt.plot(results['BN_reg=%s_drop=%s' %(reg_tag[j], drop)]['train_loss'], '-', color=colorbar[j], label='BN_reg=%s'%reg_tag[j])\n",
        "    plt.title('Loss on dropout=%s' %drop)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niJKU0w6jRgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFseg88EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni4gkkMJdRCSB/j+MhYI3M4gZugAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu8x7dJjm4EJ",
        "colab_type": "text"
      },
      "source": [
        "### Result\n",
        "***\n",
        "- 經過前面幾天的學習，我們知道BatchNormalization在預防overfitting上有很好的表現。因此，我們進行了幾種組合來測試哪種組合在模型預測上有好的表現，主要對象有這3種:BatchNormalization、Regularization、Dropout。\n",
        "- 組合邏輯:每次執行都會有BatchNormalization和Dropout，但Dropout的參數若為0則不執行Dropout，單純只做BatchNormalization；而Regularization則會有L1和L2兩種。\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=15GTD-wGg5fr5IEQGy3vdGg1ltC31Dl6Q)\n",
        "\n",
        "- 最後，我們在這4張圖可以觀察到幾點:\n",
        "    1. 只做BatchNormalization和做BatchNormalization + Dropout的效果似乎沒什麼變化(圖1~圖4 紅線)。\n",
        "    2. 我們發現加入Regularization L2，不管有沒有Dropout都會讓初始的Loss特別大，但最後仍能收斂的和紅色線一樣低。\n",
        "    3. 但在BatchNormalization搭配L1時(一樣不管有沒有Dropout)，會讓初始的Loss變得更大，而且無法收斂像紅線、藍線一樣低。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYM-ZOqknXJb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3be16b3b-8496-42bc-b0c0-8945e301c853"
      },
      "source": [
        "results = {}\n",
        "# Regularization模式\n",
        "reg_tag = {0:'off', 1:'L1', 2:'L2'}\n",
        "\n",
        "# dropout不設定，因為設定為只要大於0就可以做dropout\n",
        "# 0代表不做、1代表L1、2代表L2\n",
        "regular_class = [0, 1, 2]\n",
        "\n",
        "for i, drop in enumerate(dropout_value):\n",
        "    keras.backend.clear_session()\n",
        "    print(\"Experiment with BN + dropout=%s\" %drop)\n",
        "    model = build_mlp(x_train.shape[1:], drop_value=drop)\n",
        "    model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train,\n",
        "              epochs=EPOCH,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "\n",
        "    results['BN_drop=%s' %drop]=dict(train_loss=model.history.history['loss'],\n",
        "                                     valid_loss=model.history.history['val_loss'],\n",
        "                                     train_acc=model.history.history['acc'],\n",
        "                                     valid_acc=model.history.history['val_acc'])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experiment with BN + dropout=0\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 3s 55us/step - loss: 1.9032 - acc: 0.3305 - val_loss: 1.6984 - val_acc: 0.3972\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.6040 - acc: 0.4349 - val_loss: 1.5962 - val_acc: 0.4338\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.4952 - acc: 0.4760 - val_loss: 1.5442 - val_acc: 0.4492\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.4186 - acc: 0.5010 - val_loss: 1.5066 - val_acc: 0.4638\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.3552 - acc: 0.5257 - val_loss: 1.4786 - val_acc: 0.4713\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.3003 - acc: 0.5475 - val_loss: 1.4562 - val_acc: 0.4842\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.2519 - acc: 0.5656 - val_loss: 1.4422 - val_acc: 0.4905\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.2078 - acc: 0.5823 - val_loss: 1.4358 - val_acc: 0.4928\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.1666 - acc: 0.5985 - val_loss: 1.4254 - val_acc: 0.4968\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.1235 - acc: 0.6124 - val_loss: 1.4183 - val_acc: 0.4996\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.0867 - acc: 0.6288 - val_loss: 1.4117 - val_acc: 0.5046\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.0489 - acc: 0.6455 - val_loss: 1.4141 - val_acc: 0.5027\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.0135 - acc: 0.6565 - val_loss: 1.4107 - val_acc: 0.5061\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 0.9744 - acc: 0.6718 - val_loss: 1.4070 - val_acc: 0.5113\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 0.9410 - acc: 0.6838 - val_loss: 1.4349 - val_acc: 0.5004\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 0.9075 - acc: 0.6995 - val_loss: 1.4239 - val_acc: 0.5101\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 0.8743 - acc: 0.7083 - val_loss: 1.4325 - val_acc: 0.5139\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.8411 - acc: 0.7222 - val_loss: 1.4315 - val_acc: 0.5133\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 0.8083 - acc: 0.7337 - val_loss: 1.4464 - val_acc: 0.5142\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.7740 - acc: 0.7473 - val_loss: 1.4788 - val_acc: 0.5047\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 0.7464 - acc: 0.7582 - val_loss: 1.4711 - val_acc: 0.5078\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 0.7164 - acc: 0.7694 - val_loss: 1.4804 - val_acc: 0.5104\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 0.6844 - acc: 0.7808 - val_loss: 1.5306 - val_acc: 0.5108\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 0.6565 - acc: 0.7916 - val_loss: 1.5150 - val_acc: 0.5067\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.6252 - acc: 0.8051 - val_loss: 1.5366 - val_acc: 0.5058\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 0.5988 - acc: 0.8125 - val_loss: 1.5426 - val_acc: 0.5125\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.5713 - acc: 0.8255 - val_loss: 1.5451 - val_acc: 0.5109\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.5439 - acc: 0.8350 - val_loss: 1.5694 - val_acc: 0.5082\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 0.5188 - acc: 0.8434 - val_loss: 1.6444 - val_acc: 0.4948\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 0.4960 - acc: 0.8527 - val_loss: 1.6226 - val_acc: 0.5050\n",
            "Experiment with BN + dropout=0.15\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 3s 57us/step - loss: 2.1367 - acc: 0.2653 - val_loss: 1.7459 - val_acc: 0.3833\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.8417 - acc: 0.3495 - val_loss: 1.6314 - val_acc: 0.4202\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.7430 - acc: 0.3830 - val_loss: 1.5775 - val_acc: 0.4358\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.6758 - acc: 0.4053 - val_loss: 1.5350 - val_acc: 0.4490\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.6301 - acc: 0.4217 - val_loss: 1.5032 - val_acc: 0.4620\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.5911 - acc: 0.4351 - val_loss: 1.4766 - val_acc: 0.4740\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.5532 - acc: 0.4463 - val_loss: 1.4570 - val_acc: 0.4782\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.5280 - acc: 0.4551 - val_loss: 1.4398 - val_acc: 0.4869\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 2s 47us/step - loss: 1.5045 - acc: 0.4617 - val_loss: 1.4228 - val_acc: 0.4928\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 2s 47us/step - loss: 1.4757 - acc: 0.4723 - val_loss: 1.4112 - val_acc: 0.4944\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.4638 - acc: 0.4797 - val_loss: 1.3999 - val_acc: 0.4960\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4394 - acc: 0.4881 - val_loss: 1.3885 - val_acc: 0.5031\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4203 - acc: 0.4952 - val_loss: 1.3798 - val_acc: 0.5070\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.3998 - acc: 0.4996 - val_loss: 1.3666 - val_acc: 0.5130\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.3889 - acc: 0.5043 - val_loss: 1.3640 - val_acc: 0.5127\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.3757 - acc: 0.5100 - val_loss: 1.3531 - val_acc: 0.5122\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.3591 - acc: 0.5141 - val_loss: 1.3454 - val_acc: 0.5160\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.3427 - acc: 0.5235 - val_loss: 1.3386 - val_acc: 0.5192\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.3306 - acc: 0.5261 - val_loss: 1.3339 - val_acc: 0.5203\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.3185 - acc: 0.5293 - val_loss: 1.3267 - val_acc: 0.5203\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.3025 - acc: 0.5341 - val_loss: 1.3259 - val_acc: 0.5254\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.2945 - acc: 0.5384 - val_loss: 1.3185 - val_acc: 0.5289\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.2798 - acc: 0.5441 - val_loss: 1.3126 - val_acc: 0.5281\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.2726 - acc: 0.5456 - val_loss: 1.3099 - val_acc: 0.5272\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.2609 - acc: 0.5483 - val_loss: 1.3106 - val_acc: 0.5284\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.2437 - acc: 0.5558 - val_loss: 1.3003 - val_acc: 0.5335\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.2344 - acc: 0.5601 - val_loss: 1.2971 - val_acc: 0.5365\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.2185 - acc: 0.5643 - val_loss: 1.2899 - val_acc: 0.5372\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.2121 - acc: 0.5663 - val_loss: 1.2920 - val_acc: 0.5359\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.2118 - acc: 0.5679 - val_loss: 1.2847 - val_acc: 0.5381\n",
            "Experiment with BN + dropout=0.25\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 3s 58us/step - loss: 2.2393 - acc: 0.2370 - val_loss: 1.7692 - val_acc: 0.3724\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.9659 - acc: 0.3114 - val_loss: 1.6785 - val_acc: 0.4038\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.8638 - acc: 0.3408 - val_loss: 1.6237 - val_acc: 0.4266\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.7953 - acc: 0.3623 - val_loss: 1.5825 - val_acc: 0.4389\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.7470 - acc: 0.3791 - val_loss: 1.5540 - val_acc: 0.4481\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.7069 - acc: 0.3912 - val_loss: 1.5309 - val_acc: 0.4631\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.6745 - acc: 0.4028 - val_loss: 1.5109 - val_acc: 0.4634\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.6474 - acc: 0.4100 - val_loss: 1.4934 - val_acc: 0.4686\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.6280 - acc: 0.4170 - val_loss: 1.4780 - val_acc: 0.4760\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.6032 - acc: 0.4259 - val_loss: 1.4682 - val_acc: 0.4779\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.5850 - acc: 0.4311 - val_loss: 1.4528 - val_acc: 0.4832\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.5646 - acc: 0.4388 - val_loss: 1.4419 - val_acc: 0.4859\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.5481 - acc: 0.4462 - val_loss: 1.4325 - val_acc: 0.4885\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.5338 - acc: 0.4482 - val_loss: 1.4236 - val_acc: 0.4920\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.5238 - acc: 0.4530 - val_loss: 1.4145 - val_acc: 0.4942\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.5057 - acc: 0.4615 - val_loss: 1.4089 - val_acc: 0.4953\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.4966 - acc: 0.4628 - val_loss: 1.3991 - val_acc: 0.4966\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.4889 - acc: 0.4671 - val_loss: 1.3917 - val_acc: 0.5001\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.4749 - acc: 0.4691 - val_loss: 1.3850 - val_acc: 0.5033\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.4675 - acc: 0.4725 - val_loss: 1.3793 - val_acc: 0.5041\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.4558 - acc: 0.4789 - val_loss: 1.3710 - val_acc: 0.5102\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4467 - acc: 0.4818 - val_loss: 1.3687 - val_acc: 0.5087\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4394 - acc: 0.4855 - val_loss: 1.3622 - val_acc: 0.5105\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.4268 - acc: 0.4878 - val_loss: 1.3563 - val_acc: 0.5131\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4195 - acc: 0.4905 - val_loss: 1.3560 - val_acc: 0.5153\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4009 - acc: 0.4989 - val_loss: 1.3481 - val_acc: 0.5168\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 2s 47us/step - loss: 1.3967 - acc: 0.4999 - val_loss: 1.3411 - val_acc: 0.5196\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.3920 - acc: 0.5006 - val_loss: 1.3363 - val_acc: 0.5214\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.3867 - acc: 0.5019 - val_loss: 1.3358 - val_acc: 0.5204\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.3820 - acc: 0.5034 - val_loss: 1.3284 - val_acc: 0.5200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N10JVWrhnnkj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "15b1a113-25e8-4de5-dfdf-81111eac0b44"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "colorbar = ['r', 'g', 'b', 'y', 'm']\n",
        "for i, drop in enumerate(dropout_value):\n",
        "    plt.plot(results['BN_drop=%s' % drop]['train_loss'], '-', color=colorbar[i], label='BN_drop=%s'%drop)\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wimgo8n6xwsi",
        "colab_type": "text"
      },
      "source": [
        "- 最後最後，我們去觀察那條被壓縮很低的BatchNormalization與Dropout結合的狀況:\n",
        "  1. 可以看到只做BatchNormalization的效果就已經很好，不需要再搭配其他的組合\n",
        "  "
      ]
    }
  ]
}